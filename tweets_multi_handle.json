{
  "scrape_timestamp": "2025-08-22 17:17:01",
  "handles_scraped": [
    "elonmusk",
    "sama",
    "karpathy",
    "naval",
    "pmarca",
    "balajis"
  ],
  "individual_results": [
    {
      "handle": "elonmusk",
      "url": "http://127.0.0.1:8080/elonmusk",
      "scrape_timestamp": "2025-08-22 17:16:58",
      "tweets_count": 0,
      "new_tweets_count": 0,
      "skipped_tweets_count": 20,
      "tweets": [],
      "filtered_out_count": 0,
      "ai_classification_enabled": true,
      "ai_provider": "gpt",
      "handle_config": {
        "min_score": 6,
        "context": "Elon Musk tech/business content (Tesla, SpaceX, xAI, Neuralink, major announcements)"
      }
    },
    {
      "handle": "sama",
      "url": "http://127.0.0.1:8080/sama",
      "scrape_timestamp": "2025-08-22 17:16:58",
      "tweets_count": 20,
      "new_tweets_count": 3,
      "skipped_tweets_count": 0,
      "tweets": [
        {
          "tweet_url": "/sama/status/1957849495733166587#m",
          "tweet_id": "1957849495733166587",
          "is_retweet": false,
          "is_pinned": false,
          "author": "Sam Altman",
          "username": "@sama",
          "date": "Aug 19",
          "full_date": "Aug 19, 2025 Â· 4:57 PM UTC",
          "text": "ChatGPT Go launches in India!\n\nLooking forward to making ChatGPT more affordable in India first, and then learning from feedback to expand to other countries.",
          "quoted_tweet": {
            "author": "Nick Turley",
            "username": "@nickaturley",
            "date": "Aug 19",
            "text": "We just launched ChatGPT Go in India, a new subscription tier that gives users in India more access to our most popular features: 10x higher message limits, 10x more image generations, 10x more file uploads, and 2x longer memory compared with our free tier. All for Rs. 399. ðŸ‡®ðŸ‡³",
            "link": "/nickaturley/status/1957613818902892985#m"
          },
          "media": [],
          "stats": {
            "replies": "",
            "retweets": "",
            "likes": ""
          },
          "handle": "sama",
          "importance_score": 8,
          "importance_reason": "High priority keyword (AI not available - using keywords)",
          "ai_provider": "gpt"
        },
        {
          "tweet_url": "/sama/status/1955095125597753567#m",
          "tweet_id": "1955095125597753567",
          "is_retweet": false,
          "is_pinned": false,
          "author": "Sam Altman",
          "username": "@sama",
          "date": "Aug 12",
          "full_date": "Aug 12, 2025 Â· 2:32 AM UTC",
          "text": "I hope someone will get counter-discovery on this, I and many others would love to know what's been happening.\n\nBut OpenAI will just stay focused on making great products.",
          "quoted_tweet": null,
          "media": [],
          "stats": {
            "likes": ""
          },
          "handle": "sama",
          "importance_score": 7,
          "importance_reason": "Company keyword (AI not available - using keywords)",
          "ai_provider": "gpt"
        },
        {
          "tweet_url": "/sama/status/1954703747495649670#m",
          "tweet_id": "1954703747495649670",
          "is_retweet": false,
          "is_pinned": false,
          "author": "Sam Altman",
          "username": "@sama",
          "date": "Aug 11",
          "full_date": "Aug 11, 2025 Â· 12:37 AM UTC",
          "text": "If you have been following the GPT-5 rollout, one thing you might be noticing is how much of an attachment some people have to specific AI models. It feels different and stronger than the kinds of attachment people have had to previous kinds of technology (and so suddenly deprecating old models that users depended on in their workflows was a mistake).\n\nThis is something weâ€™ve been closely tracking for the past year or so but still hasnâ€™t gotten much mainstream attention (other than when we released an update to GPT-4o that was too sycophantic).\n\n(This is just my current thinking, and not yet an official OpenAI position.)\n\nPeople have used technology including AI in self-destructive ways; if a user is in a mentally fragile state and prone to delusion, we do not want the AI to reinforce that. Most users can keep a clear line between reality and fiction or role-play, but a small percentage cannot. We value user freedom as a core principle, but we also feel responsible in how we introduce new technology with new risks.\n\nEncouraging delusion in a user that is having trouble telling the difference between reality and fiction is an extreme case and itâ€™s pretty clear what to do, but the concerns that worry me most are more subtle. There are going to be a lot of edge cases, and generally we plan to follow the principle of â€œtreat adult users like adultsâ€, which in some cases will include pushing back on users to ensure they are getting what they really want.\n\nA lot of people effectively use ChatGPT as a sort of therapist or life coach, even if they wouldnâ€™t describe it that way. This can be really good! A lot of people are getting value from it already today.\n\nIf people are getting good advice, leveling up toward their own goals, and their life satisfaction is increasing over years, we will be proud of making something genuinely helpful, even if they use and rely on ChatGPT a lot. If, on the other hand, users have a relationship with ChatGPT where they think they feel better after talking but theyâ€™re unknowingly nudged away from their longer term well-being (however they define it), thatâ€™s bad. Itâ€™s also bad, for example, if a user wants to use ChatGPT less and feels like they cannot.\n\nI can imagine a future where a lot of people really trust ChatGPTâ€™s advice for their most important decisions. Although that could be great, it makes me uneasy. But I expect that it is coming to some degree, and soon billions of people may be talking to an AI in this way. So we (we as in society, but also we as in OpenAI) have to figure out how to make it a big net positive.\n\nThere are several reasons I think we have a good shot at getting this right. We have much better tech to help us measure how we are doing than previous generations of technology had. For example, our product can talk to users to get a sense for how they are doing with their short- and long-term goals, we can explain sophisticated and nuanced issues to our models, and much more.",
          "quoted_tweet": null,
          "media": [],
          "stats": {
            "replies": "",
            "retweets": "",
            "likes": ""
          },
          "handle": "sama",
          "importance_score": 8,
          "importance_reason": "High priority keyword (AI not available - using keywords)",
          "ai_provider": "gpt"
        }
      ],
      "filtered_out_count": 17,
      "ai_classification_enabled": true,
      "ai_provider": "gpt",
      "handle_config": {
        "min_score": 7,
        "context": "Sam Altman content (OpenAI, AI development, tech leadership, industry insights)"
      }
    },
    {
      "handle": "karpathy",
      "url": "http://127.0.0.1:8080/karpathy",
      "scrape_timestamp": "2025-08-22 17:16:59",
      "tweets_count": 21,
      "new_tweets_count": 13,
      "skipped_tweets_count": 0,
      "tweets": [
        {
          "tweet_url": "/karpathy/status/1617979122625712128#m",
          "tweet_id": "1617979122625712128",
          "is_retweet": false,
          "is_pinned": true,
          "author": "Andrej Karpathy",
          "username": "@karpathy",
          "date": "24 Jan 2023",
          "full_date": "Jan 24, 2023 Â· 8:14 PM UTC",
          "text": "The hottest new programming language is English",
          "quoted_tweet": null,
          "media": [],
          "stats": {
            "replies": "",
            "retweets": "",
            "quotes": "",
            "likes": ""
          },
          "handle": "karpathy",
          "importance_score": 9,
          "importance_reason": "Pinned tweet (AI not available - using keywords)",
          "ai_provider": "gpt"
        },
        {
          "tweet_url": "/karpathy/status/1957574489358873054#m",
          "tweet_id": "1957574489358873054",
          "is_retweet": false,
          "is_pinned": false,
          "author": "Andrej Karpathy",
          "username": "@karpathy",
          "date": "Aug 18",
          "full_date": "Aug 18, 2025 Â· 10:45 PM UTC",
          "text": "I get ~10 spam calls per day (various automated voicemails, \"loan pre-approval\" etc) and ~5 spam messages per day (usually phishing).\n\n- I have AT&T Active Armor, all of the above still slips through.\n- All of the above is always from new, unique numbers so blocking doesn't work.\n- I am on all Do Not Call lists.\n- I have iOS \"Silence Unknown Callers\" on, but even if it catches & silences them I still get the notifications.\n\nNot sure if other people are seeing something similar or figured out anything that works",
          "quoted_tweet": null,
          "media": [],
          "stats": {
            "replies": "",
            "likes": ""
          },
          "handle": "karpathy",
          "importance_score": 6,
          "importance_reason": "Tech keyword (AI not available - using keywords)",
          "ai_provider": "gpt"
        },
        {
          "tweet_url": "/karpathy/status/1957561075744010253#m",
          "tweet_id": "1957561075744010253",
          "is_retweet": false,
          "is_pinned": false,
          "author": "Andrej Karpathy",
          "username": "@karpathy",
          "date": "Aug 18",
          "full_date": "Aug 18, 2025 Â· 9:51 PM UTC",
          "text": "Ok, spent an ~hour sifting through submissions. The biggest challenge was the spam, as majority of replies are people linking to their own existing projects, not things made for the challenge. Of the ones that were:\n\nWinner: I most enjoyed this one from@uncertainsys- OmegaQuest. He's solving Humanity's Last Exam problems with heavy AI use in the loop on video. Actually I really identified with the long pauses and general confusion in trying to use the current state of the art systems in learning something hard and new, where they are simultaneously so tantalizingly helpful at the margins, but still really poor overall, compared to an imagined human expert tutor. The \"explanations\" are... not. But I love the tenacity on display in working out something hard and seeing how far you can get with AI. A good reminder how it's better than what was, but also so far from what could be.nitter.net/uncertainsys/status/19â€¦Shoutout to@measure_planfor cool \"visual vibe coding\" projects, e.g. new musical instrumentsnitter.net/measure_plan/status/19â€¦A few of people commented that the challenge shouldn't have to be only for projects uniquely made for the challenge. If that were the case then shoutout to@evanliinet al. who linked to tinytpu, i really like the animated diagram, i haven't seen that before.nitter.net/evanliin/status/195749â€¦Shoutout to@ChrisChipMonkfor partially incepting the experiment a while ago withnitter.net/ChrisChipMonk/status/1â€¦but I basically come out agreeing with@nearcyanin his earlier commentnitter.net/nearcyan/status/193839â€¦, maybe even $5K isn't :)",
          "quoted_tweet": null,
          "media": [],
          "stats": {},
          "handle": "karpathy",
          "importance_score": 6,
          "importance_reason": "Tech keyword (AI not available - using keywords)",
          "ai_provider": "gpt"
        },
        {
          "tweet_url": "/karpathy/status/1956765908078387382#m",
          "tweet_id": "1956765908078387382",
          "is_retweet": false,
          "is_pinned": false,
          "author": "Andrej Karpathy",
          "username": "@karpathy",
          "date": "Aug 16",
          "full_date": "Aug 16, 2025 Â· 5:12 PM UTC",
          "text": "I am (slowly) re-reading the Tolkien legendarium (of which Lord of the Rings is a small part). The whole body of work is so incredible and there's nothing else like it... it dilutes other worlds of fiction. Wait - your story doesn't have a comprehensive history/mythology spanning multiple ages all the way back to a creation myth as detailed in separate volumes? You didn't first invent new languages and dialects for your characters? You didn't pack it with powerful themes and stories written it in a beautiful, archaic style and compose poems and songs alongside? It didn't take you multiple decades of iteration? And what of all the uncharted territory still remaining? Is Tom Bombadil one of the Ainur. Where are the Entwives. What happened to the two unaccounted Istari. Can we hear more about what it was like in CuiviÃ©nen when the elves first awoke? Or to see the light of the two trees of Valinor. Or of the splendor of the caves of Aglarond.\n\nWhat's most on my mind though - the Tolkien legendarium is imo a concrete example of a height of culture. Does AI, today or soon, make it easier to reach this high via empowerment in both writing and ideation? Or harder, when quick wins are tempting and ~free, and an independent ability to create is stifled. If such a body of work is made again but now with heavy AI assistance, does it inspire the same wonder? What if thousands of them come out on demand with just a prompt? Why do you feel cheated when you learn that something your read was AI generated? Is it transient or a function of capability? Is it slop? What is slop? Or is wonder inseparable from its own creation myth of a lifelong obsession of a mind like your own? So many questions.",
          "quoted_tweet": null,
          "media": [],
          "stats": {
            "replies": "",
            "retweets": "",
            "likes": ""
          },
          "handle": "karpathy",
          "importance_score": 6,
          "importance_reason": "Tech keyword (AI not available - using keywords)",
          "ai_provider": "gpt"
        },
        {
          "tweet_url": "/karpathy/status/1954224651443544436#m",
          "tweet_id": "1954224651443544436",
          "is_retweet": false,
          "is_pinned": false,
          "author": "Andrej Karpathy",
          "username": "@karpathy",
          "date": "Aug 9",
          "full_date": "Aug 9, 2025 Â· 4:53 PM UTC",
          "text": "I'm noticing that due to (I think?) a lot of benchmarkmaxxing on long horizon tasks, LLMs are becoming a little too agentic by default, a little beyond my average use case.\n\nFor example in coding, the models now tend to reason for a fairly long time, they have an inclination to start listing and grepping files all across the entire repo, they do repeated web searchers, they over-analyze and over-think little rare edge cases even in code that is knowingly incomplete and under active development, and often come back ~minutes later even for simple queries.\n\nThis might make sense for long-running tasks but it's less of a good fit for more \"in the loop\" iterated development that I still do a lot of, or if I'm just looking for a quick spot check before running a script, just in case I got some indexing wrong or made some dumb error. So I find myself quite often stopping the LLMs with variations of \"Stop, you're way overthinking this. Look at only this single file. Do not use any tools. Do not over-engineer\", etc.\n\nBasically as the default starts to slowly creep into the \"ultrathink\" super agentic mode, I feel a need for the reverse, and more generally good ways to indicate or communicate intent / stakes, from \"just have a quick look\" all the way to \"go off for 30 minutes, come back when absolutely certain\".",
          "quoted_tweet": null,
          "media": [],
          "stats": {
            "likes": ""
          },
          "handle": "karpathy",
          "importance_score": 6,
          "importance_reason": "Tech keyword (AI not available - using keywords)",
          "ai_provider": "gpt"
        },
        {
          "tweet_url": "/karpathy/status/1952076108565991588#m",
          "tweet_id": "1952076108565991588",
          "is_retweet": false,
          "is_pinned": false,
          "author": "Andrej Karpathy",
          "username": "@karpathy",
          "date": "Aug 3",
          "full_date": "Aug 3, 2025 Â· 6:36 PM UTC",
          "text": "Shower of thoughts: Instead of keeping your Twitter/ð• payout, direct it towards a \"PayoutChallenge\" of your choosing - anything you want more of in the world!\n\nHere is mine for this round, combining my last 3 payouts of $5478.51:\n\nIt is imperative that humanity not fall while AI ascends. Humanity has to continue to rise, become better alongside. Create something that is specifically designed to uplift team human. Definition intentionally left a bit vague to keep some entropy around people's interpretation, but imo examples include:\n- Any piece of software that aids explanation, visualization, memorization, inspiration, understanding, coordination, etc...\n- It doesn't have to be too lofty, e.g. it can be a specific educational article/video explaining something some other people could benefit from or that you have unique knowledge of.\n- Prompts/agents for explanation, e.g. along the lines of recently released ChatGPT study mode.\n- Related works of art\n\nThis challenge will run for 2 weeks until Aug 17th EOD PST. Submit your contribution as a reply. It has to be something that was uniquely created for this challenge and would not exist otherwise. Criteria includes execution, leverage, novelty, inspiration, aesthetics, amusement. People can upvote submissions by liking, this \"people's choice\" will also be a factor. I will decide the winner on Aug 17th and send $5478.51 :)",
          "quoted_tweet": null,
          "media": [],
          "stats": {
            "likes": ""
          },
          "handle": "karpathy",
          "importance_score": 8,
          "importance_reason": "High priority keyword (AI not available - using keywords)",
          "ai_provider": "gpt"
        },
        {
          "tweet_url": "/karpathy/status/1946745524033593739#m",
          "tweet_id": "1946745524033593739",
          "is_retweet": false,
          "is_pinned": false,
          "author": "Andrej Karpathy",
          "username": "@karpathy",
          "date": "Jul 20",
          "full_date": "Jul 20, 2025 Â· 1:34 AM UTC",
          "text": "Hi@gmaildoes the \"report phishing\" button do anything",
          "quoted_tweet": null,
          "media": [
            {
              "type": "image",
              "src": "/pic/media%2FGwQ6gB4X0AEFbUy.jpg%3Fname%3Dsmall%26format%3Dwebp",
              "alt": ""
            }
          ],
          "stats": {
            "likes": ""
          },
          "handle": "karpathy",
          "importance_score": 6,
          "importance_reason": "Tech keyword (AI not available - using keywords)",
          "ai_provider": "gpt"
        },
        {
          "tweet_url": "/karpathy/status/1946325810618700033#m",
          "tweet_id": "1946325810618700033",
          "is_retweet": false,
          "is_pinned": false,
          "author": "Andrej Karpathy",
          "username": "@karpathy",
          "date": "Jul 18",
          "full_date": "Jul 18, 2025 Â· 9:46 PM UTC",
          "text": "\"Using a better model for analysis\" ðŸ¤¨\nI didn't realize I was using haiku all this time, no idea when claude code snuck this one in rofl.",
          "quoted_tweet": null,
          "media": [
            {
              "type": "image",
              "src": "/pic/media%2FGwK7Mq_XYAA1W0x.jpg%3Fname%3Dsmall%26format%3Dwebp",
              "alt": ""
            }
          ],
          "stats": {
            "likes": ""
          },
          "handle": "karpathy",
          "importance_score": 6,
          "importance_reason": "Tech keyword (AI not available - using keywords)",
          "ai_provider": "gpt"
        },
        {
          "tweet_url": "/karpathy/status/1945979830740435186#m",
          "tweet_id": "1945979830740435186",
          "is_retweet": false,
          "is_pinned": false,
          "author": "Andrej Karpathy",
          "username": "@karpathy",
          "date": "Jul 17",
          "full_date": "Jul 17, 2025 Â· 10:52 PM UTC",
          "text": "Diffusion video models but now - **realtime**!\n\nSimple video filters are real-time but can only do basic re-coloring and styles. Video diffusion models (Veo and friends) are magic, but they take many seconds/minutes to generate. MirageLSD is real-time magic. Unlike simple video filters, diffusion models actually *understand* what they are looking at, so they can style all parts of the feed intelligently (e.g. putting hats on heads, or light sabers into hands, etc.). And they are arbitrarily steerable, e.g. by text prompts.\n\nCustomizable, intelligent video filters unlock many cool ideas over time:\n- transform camera feeds into alternate realities\n- direct and shoot your own movies, acting out scenes with props. Realtime => instant feedback/review.\n- vibe code games around just simple spheres/blocks, then use a real-time diffusion model to texture your game to make it beautiful.\n- style and customize any video feed: games, videos, ... e.g. Skyrim but \"MORE EPIC\"? DOOM II but modern Unreal Engine quality with just a prompt? Horror movie but \"cute, pink and bunnies only\"? I don't know!\n- zoom call backgrounds+++\n- real-time try on clothes virtually\n- glasses: e.g. cartoonify your vision in real time?\n- we can now build Harry Potter Mirror of Erised, showing the \"raw feed\" of you in the mirror but augmented with your deepest desires (as inferred by the AI).\n- I don't know, I'm probably missing the biggest one, so many things!\n\n(Disclosure I am (very small) angel investor in Decart, I was excited because imo this technology will get very good very fast and it feels general, powerful but it's also technically very difficult. Congrats on the launch to the team!)",
          "quoted_tweet": {
            "author": "Decart",
            "username": "@DecartAI",
            "date": "Jul 17",
            "text": "Introducing MirageLSD: The First Live-Stream Diffusion (LSD) AI Model\n\nInput any video stream, from a camera or video chat to a computer screen or game, and transform it into any world you desire, in real-time (<40ms latency).\n\nHereâ€™s how it works (w/ demo you can use!):",
            "link": "/DecartAI/status/1945947692871692667#m"
          },
          "media": [
            {
              "type": "image",
              "src": "/pic/amplify_video_thumb%2F1945947630892470273%2Fimg%2FtMWGyDcoT3KmQg0U.jpg%3Fname%3Dsmall%26format%3Dwebp",
              "alt": ""
            },
            {
              "type": "video",
              "thumbnail": "/pic/amplify_video_thumb%2F1945947630892470273%2Fimg%2FtMWGyDcoT3KmQg0U.jpg%3Fname%3Dsmall%26format%3Dwebp"
            }
          ],
          "stats": {
            "likes": ""
          },
          "handle": "karpathy",
          "importance_score": 8,
          "importance_reason": "High priority keyword (AI not available - using keywords)",
          "ai_provider": "gpt"
        },
        {
          "tweet_url": "/karpathy/status/1944435412489171119#m",
          "tweet_id": "1944435412489171119",
          "is_retweet": false,
          "is_pinned": false,
          "author": "Andrej Karpathy",
          "username": "@karpathy",
          "date": "Jul 13",
          "full_date": "Jul 13, 2025 Â· 4:35 PM UTC",
          "text": "Scaling up RL is all the rage right now, I had a chat with a friend about it yesterday. I'm fairly certain RL will continue to yield more intermediate gains, but I also don't expect it to be the full story. RL is basically \"hey this happened to go well (/poorly), let me slightly increase (/decrease) the probability of every action I took for the future\". You get a lot more leverage from verifier functions than explicit supervision, this is great. But first, it looks suspicious asymptotically - once the tasks grow to be minutes/hours of interaction long, you're really going to do all that work just to learn a single scalar outcome at the very end, to directly weight the gradient? Beyond asymptotics and second, this doesn't feel like the human mechanism of improvement for majority of intelligence tasks. There's significantly more bits of supervision we extract per rollout via a review/reflect stage along the lines of \"what went well? what didn't go so well? what should I try next time?\" etc. and the lessons from this stage feel explicit, like a new string to be added to the system prompt for the future, optionally to be distilled into weights (/intuition) later a bit like sleep. In English, we say something becomes \"second nature\" via this process, and we're missing learning paradigms like this. The new Memory feature is maybe a primordial version of this in ChatGPT, though it is only used for customization not problem solving. Notice that there is no equivalent of this for e.g. Atari RL because there are no LLMs and no in-context learning in those domains. \n\nExample algorithm: given a task, do a few rollouts, stuff them all into one context window (along with the reward in each case), use a meta-prompt to review/reflect on what went well or not to obtain string \"lesson\", to be added to system prompt (or more generally modify the current lessons database). Many blanks to fill in, many tweaks possible, not obvious.\n\nExample of lesson: we know LLMs can't super easily see letters due to tokenization and can't super easily count inside the residual stream, hence 'r' in 'strawberry' being famously difficult. Claude system prompt had a \"quick fix\" patch - a string was added along the lines of \"If the user asks you to count letters, first separate them by commas and increment an explicit counter each time and do the task like that\". This string is the \"lesson\", explicitly instructing the model how to complete the counting task, except the question is how this might fall out from agentic practice, instead of it being hard-coded by an engineer, how can this be generalized, and how lessons can be distilled over time to not bloat context windows indefinitely.\n\nTLDR: RL will lead to more gains because when done well, it is a lot more leveraged, bitter-lesson-pilled, and superior to SFT. It doesn't feel like the full story, especially as rollout lengths continue to expand. There are more S curves to find beyond, possibly specific to LLMs and without analogues in game/robotics-like environments, which is exciting.",
          "quoted_tweet": null,
          "media": [],
          "stats": {
            "likes": ""
          },
          "handle": "karpathy",
          "importance_score": 7,
          "importance_reason": "Company keyword (AI not available - using keywords)",
          "ai_provider": "gpt"
        },
        {
          "tweet_url": "/karpathy/status/1943411187296686448#m",
          "tweet_id": "1943411187296686448",
          "is_retweet": false,
          "is_pinned": false,
          "author": "Andrej Karpathy",
          "username": "@karpathy",
          "date": "Jul 10",
          "full_date": "Jul 10, 2025 Â· 8:45 PM UTC",
          "text": "I often rant about how 99% of attention is about to be LLM attention instead of human attention. What does a research paper look like for an LLM instead of a human? Itâ€™s definitely not a pdf. There is huge space for an extremely valuable â€œresearch appâ€ that figures this out.",
          "quoted_tweet": {
            "author": "Michael Levin",
            "username": "@drmichaellevin",
            "date": "Jul 10",
            "text": "I'm constantly irritated that I don't have time to read the torrent of cool papers coming faster and faster from amazing people in relevant fields.  Other scientists have the same issue and have no time to read most of my lengthy conceptual papers either.  So whom are we writing these papers for?\n\nI guess, at least until they fall in to the same issue from their own work, AI's will be the only ones who actually have the bandwidth to read all this stuff.  I'm not specifically talking about today's language models - let's assume we mean whatever inevitable AI shows up, that is able to read the literature and have impact on the research (whether by talking to humans or by running lab automation/robot scientist platforms).\n\nSo then: how should we be writing, knowing that a lot of our audience will be AI (plus cyborgs, hybrots, augmented humans, etc.)?  Maybe it's too early to know what to do, but we better start thinking about it because assuming our audience will always be today's humans seems untenable. Taking seriously the idea that someday the impactful audience will be very different, and that the things we write now are in some sense a training set for truly diverse future beings, how does our writing change? or does it?\n\nwhat say you@danfaggella@mpshanahan@Plinz@blaiseaguera?",
            "link": "/drmichaellevin/status/1943321140128030753#m"
          },
          "media": [],
          "stats": {
            "likes": ""
          },
          "handle": "karpathy",
          "importance_score": 6,
          "importance_reason": "Tech keyword (AI not available - using keywords)",
          "ai_provider": "gpt"
        },
        {
          "tweet_url": "/karpathy/status/1941616674094170287#m",
          "tweet_id": "1941616674094170287",
          "is_retweet": false,
          "is_pinned": false,
          "author": "Andrej Karpathy",
          "username": "@karpathy",
          "date": "Jul 5",
          "full_date": "Jul 5, 2025 Â· 9:54 PM UTC",
          "text": "How to build a thriving open source community by writing code like bacteria do ðŸ¦ . Bacterial code (genomes) are:\n\n- small (each line of code costs energy)\n- modular (organized into groups of swappable operons)\n- self-contained (easily \"copy paste-able\" via horizontal gene transfer)\n\nIf chunks of code are small, modular, self-contained and trivial to copy-and-paste, the community can thrive via horizontal gene transfer. For any function (gene) or class (operon) that you write: can you imagine someone going \"yoink\" without knowing the rest of your code or having to import anything new, to gain a benefit? Could your code be a trending GitHub gist?\n\nThis coding style guide has allowed bacteria to colonize every ecological nook from cold to hot to acidic or alkaline in the depths of the Earth and the vacuum of space, along with an insane diversity of carbon anabolism, energy metabolism, etc. It excels at rapid prototyping but... it can't build complex life. By comparison, the eukaryotic genome is a significantly larger, more complex, organized and coupled monorepo. Significantly less inventive but necessary for complex life - for building entire organs and coordinating their activity. With our advantage of intelligent design, it should possible to take advantage of both. Build a eukaryotic monorepo backbone if you have to, but maximize bacterial DNA.",
          "quoted_tweet": null,
          "media": [
            {
              "type": "image",
              "src": "/pic/media%2FGvIB64XWYAAg1B8.jpg%3Fname%3Dsmall%26format%3Dwebp",
              "alt": ""
            }
          ],
          "stats": {
            "retweets": "",
            "likes": ""
          },
          "handle": "karpathy",
          "importance_score": 7,
          "importance_reason": "Company keyword (AI not available - using keywords)",
          "ai_provider": "gpt"
        },
        {
          "tweet_url": "/karpathy/status/1940181840201228384#m",
          "tweet_id": "1940181840201228384",
          "is_retweet": false,
          "is_pinned": false,
          "author": "Andrej Karpathy",
          "username": "@karpathy",
          "date": "Jul 1",
          "full_date": "Jul 1, 2025 Â· 10:52 PM UTC",
          "text": "Test-based certification is the only way forward in food, eager to see more over time.\n\nFood is not simple anymore - it is a complex, industrial product with global supply and processing chains. Contamination can be introduced in many stages along the way from farming to harvest, processing, packaging, transport and preparation. Examples include pesticides, nitrates, heavy metals, plastics, bacteria, etc etc. So it's not just about what food to eat, it's about which specific food item SKU, from which specific supplier, and the only way to know is to test. E.g. these two cat foods look the same, the ingredients might look the same, but the one on the left is 1000X higher in glyphosate and 100X in lead. Or e.g. this baby food formula or turmeric is loaded with heavy metals, this canned seafood, your local boba or this milk brand is seeped in plastics, or this breakfast cereal way way too high in glyphosate (real examples).\n\nI used to think that the FDA exercises oversight but the reality is that it doesn't have anywhere near enough resources to do it thoroughly and their focus is a lot more on e.g. acute microbial threats (like Salmonella, E. coli, Listeria, ...) that immediately hospitalize people, less on the rapidly growing diversity of compounds that may or may not deteriorate health over decades and that are basically treated as innocent until proven guilty under GRAS and so on. Meanwhile, the public health macro picture looks not so great - obesity up, type-2 diabetes up, fertility down (sperm count/motility), weird endocrine trends (e.g. testosterone down in men), depression and anxiety up... It wouldn't shock me if modern industrial food turns out to be a major contributor.",
          "quoted_tweet": {
            "author": "Bryan Johnson",
            "username": "@bryan_johnson",
            "date": "Jul 1",
            "text": "Something new and exciting is here\n\nDog and cat food toxin testing\n+ fund your pet's food\n+ if brand claims results, your money comes back \n+ fund more tests\n\nTogether we can rapidly test all US dog and cat food. \n\nInitial results \nBlueprint Quantified tested 22 mass-market products (12 dog foods, 10 cat foods) from 14 US national brands. \n\nGlyphosate\n+ Detected in 21 of 22 products (95%).\n+ 8 products hit the upper detection limit of 1,000 ppm\n+ Thatâ€™s 118 mg glyphosate in a 118 g serving, equivalent to maximum tolerable exposure for 68 kg human \n+ Lowest non-zero hit: 0.04 ppm (Merrick Chicken & Sweet Potato)\n\nHeavy metals\n+ mercury, lead, arsenic, and cadmium were detected in every sample\n+ arsenic: up to 0.238 ppm / 238 ppb (Sheba Seafood Wet Cat Food). 8.9 mcg per 38 g serving\n+ cadmium: up to 0.084 ppm / 83.6 ppb (Royal Canin Medium Adult Dog).\n+ lead: up to 0.343 ppm / 343 ppb (Royal Canin Indoor Adult Cat), 12.9 mcg of lead per 38 g servingÂ  (26x California Prop 65â€™s daily limit (0.5 mcg))\n+ mercury: up to 0.012 ppm / 11.8 ppb (Sheba Seafood Wet Cat Food)\n\nTop heavy metal toxicity:\n+ Wellness CORE+ Original (Dog): 43.4 Âµg/serving\n+ Nutro Natural Choice Small Breed (Dog): 42.6 Âµg/serving\n+ Blue Buffalo Homestyle Senior (Dog, wet): 35.6 Âµg/serving\n+ Royal Canin Size Health Medium Dog: 33.7 Âµg/serving\n+ Pedigree Small Dog â€œGrilled Steak & Vegâ€ (Dog): 27.9 Âµg Âµg/serving\n\nCleanest product\nPurina Friskies Surfinâ€™ & Turfinâ€™ (Cat) had non-detectable glyphosate, and the second lowest total heavy metals.",
            "link": "/bryan_johnson/status/1940112033493786979#m"
          },
          "media": [
            {
              "type": "image",
              "src": "/pic/media%2FGuym1p0XIAAfMzh.jpg%3Fname%3Dsmall%26format%3Dwebp",
              "alt": ""
            }
          ],
          "stats": {
            "likes": ""
          },
          "handle": "karpathy",
          "importance_score": 8,
          "importance_reason": "High priority keyword (AI not available - using keywords)",
          "ai_provider": "gpt"
        }
      ],
      "filtered_out_count": 8,
      "ai_classification_enabled": true,
      "ai_provider": "gpt",
      "handle_config": {
        "min_score": 6,
        "context": "Andrej Karpathy content (AI research, machine learning, technical insights)"
      }
    },
    {
      "handle": "naval",
      "url": "http://127.0.0.1:8080/naval",
      "scrape_timestamp": "2025-08-22 17:16:59",
      "tweets_count": 20,
      "new_tweets_count": 2,
      "skipped_tweets_count": 0,
      "tweets": [
        {
          "tweet_url": "/naval/status/1002103360646823936#m",
          "tweet_id": "1002103360646823936",
          "is_retweet": false,
          "is_pinned": true,
          "author": "Naval",
          "username": "@naval",
          "date": "31 May 2018",
          "full_date": "May 31, 2018 Â· 8:23 AM UTC",
          "text": "How to Get Rich (without getting lucky):",
          "quoted_tweet": null,
          "media": [],
          "stats": {
            "replies": "",
            "retweets": "",
            "quotes": "",
            "likes": ""
          },
          "handle": "naval",
          "importance_score": 9,
          "importance_reason": "Pinned tweet (AI not available - using keywords)",
          "ai_provider": "gpt"
        },
        {
          "tweet_url": "/naval/status/1952519682256466329#m",
          "tweet_id": "1952519682256466329",
          "is_retweet": false,
          "is_pinned": false,
          "author": "Naval",
          "username": "@naval",
          "date": "Aug 4",
          "full_date": "Aug 4, 2025 Â· 11:59 PM UTC",
          "text": "nav.al/hiringNivi: Weâ€™re hiring an editor for the Naval Podcast, and Naval is also hiring a chief of staff. If youâ€™re not interested in either of these, you can move on to the next episode. Let me give you some details on both of them.\n\nFirst, the editor for the Naval Podcast, which as you already know, is the most timeless and overproduced podcast in human history. The editor will be primarily editing the podcast in Descript. Theyâ€™ll be editing the transcripts for clarity and posting videos to social media to get Navalâ€™s ideas into the hands of 8 billion people on planet Earth. If youâ€™re already working on another podcast, donâ€™t hesitate to contact us. Youâ€™ll learn more with us.\n\nIf youâ€™re more of a producer than an editor, feel free to get in touch anyway. We are open to new ideas. This is a part-time role, but thereâ€™s infinite room to get into more challenging and creative problems. You donâ€™t need experience, but you need to be extremely smart and high-slope. Hereâ€™s some more details on what weâ€™re looking for.\n\nYou must have a DSM-5 level attention to detail. You must be a good writer with a nose for design, and you must get things the first time you hear them. Please send less than 750 characters about yourself to podcast@nav.al. Include links to your best work and your smartest tweet. Tell us about a hard problem youâ€™ve solved, new knowledge youâ€™re creating for fun, and share something youâ€™ve made with AI. The shorter your email, the better. \n\nThanks for considering us.\n\nChief of Staff\n\nOn to the second position. Naval is also hiring a chief of staff to work directly with him. This is independent of the podcast. Youâ€™ll be working with him to solve problems, including traveling the world to recruit engineers, researching investments, throwing events, personal tasks, and anything else he needs done.\n\nThe work will range from prestigious to pauperian. You must be extremely technical, always working, based in San Francisco and willing to travel anytime. The right person probably has a couple years of work under their belt and wants to start a company one day. Again, please send under 750 characters about yourself to chief@nav.al.\n\nInclude links to your best work and your smartest tweet. Tell us about a hard problem youâ€™ve solved, new knowledge youâ€™re creating for fun, and share something youâ€™ve made with AI. The shorter your message, the better.\n\nThanks for considering this.",
          "quoted_tweet": null,
          "media": [],
          "stats": {},
          "handle": "naval",
          "importance_score": 8,
          "importance_reason": "High priority keyword (AI not available - using keywords)",
          "ai_provider": "gpt"
        }
      ],
      "filtered_out_count": 18,
      "ai_classification_enabled": true,
      "ai_provider": "gpt",
      "handle_config": {
        "min_score": 8,
        "context": "Naval Ravikant content (startups, investing, philosophy, wealth creation)"
      }
    },
    {
      "handle": "pmarca",
      "url": "http://127.0.0.1:8080/pmarca",
      "scrape_timestamp": "2025-08-22 17:17:00",
      "tweets_count": 21,
      "new_tweets_count": 1,
      "skipped_tweets_count": 0,
      "tweets": [
        {
          "tweet_url": "/pmarca/status/1902724994607570975#m",
          "tweet_id": "1902724994607570975",
          "is_retweet": false,
          "is_pinned": true,
          "author": "Marc Andreessen ðŸ‡ºðŸ‡¸",
          "username": "@pmarca",
          "date": "Mar 20",
          "full_date": "Mar 20, 2025 Â· 2:12 PM UTC",
          "text": "THAT'S RIGHT.",
          "quoted_tweet": null,
          "media": [
            {
              "type": "image",
              "src": "/pic/ext_tw_video_thumb%2F1902724959589253120%2Fpu%2Fimg%2FEf8KguO1P_C8NyaT.jpg%3Fname%3Dsmall%26format%3Dwebp",
              "alt": ""
            },
            {
              "type": "video",
              "thumbnail": "/pic/ext_tw_video_thumb%2F1902724959589253120%2Fpu%2Fimg%2FEf8KguO1P_C8NyaT.jpg%3Fname%3Dsmall%26format%3Dwebp"
            }
          ],
          "stats": {
            "retweets": "",
            "likes": ""
          },
          "handle": "pmarca",
          "importance_score": 9,
          "importance_reason": "Pinned tweet (AI not available - using keywords)",
          "ai_provider": "gpt"
        }
      ],
      "filtered_out_count": 20,
      "ai_classification_enabled": true,
      "ai_provider": "gpt",
      "handle_config": {
        "min_score": 7,
        "context": "Marc Andreessen content (VC insights, tech trends, startups, market analysis)"
      }
    },
    {
      "handle": "balajis",
      "url": "http://127.0.0.1:8080/balajis",
      "scrape_timestamp": "2025-08-22 17:17:01",
      "tweets_count": 21,
      "new_tweets_count": 6,
      "skipped_tweets_count": 0,
      "tweets": [
        {
          "tweet_url": "/balajis/status/1947365217874416120#m",
          "tweet_id": "1947365217874416120",
          "is_retweet": false,
          "is_pinned": true,
          "author": "Balaji",
          "username": "@balajis",
          "date": "Jul 21",
          "full_date": "Jul 21, 2025 Â· 6:37 PM UTC",
          "text": "Come to Singapore on October 3.ns.com/conference2025",
          "quoted_tweet": null,
          "media": [
            {
              "type": "image",
              "src": "/pic/media%2FGwZuBbEbEAIyezg.jpg%3Fname%3Dsmall%26format%3Dwebp",
              "alt": ""
            }
          ],
          "stats": {
            "likes": ""
          },
          "handle": "balajis",
          "importance_score": 9,
          "importance_reason": "Pinned tweet (AI not available - using keywords)",
          "ai_provider": "gpt"
        },
        {
          "tweet_url": "/brian_armstrong/status/1959003696693748055#m",
          "tweet_id": "1959003696693748055",
          "is_retweet": true,
          "retweet_info": "Balaji retweeted",
          "is_pinned": false,
          "author": "Brian Armstrong",
          "username": "@brian_armstrong",
          "date": "2h",
          "full_date": "Aug 22, 2025 Â· 9:24 PM UTC",
          "text": "Fun fact: as CTO Balaji was the person most responsible for driving the launch of USDC on the Coinbase side.\n\nHere's the launch video:",
          "quoted_tweet": {
            "author": "Brian Armstrong",
            "username": "@brian_armstrong",
            "date": "8h",
            "text": "The one and only, legendary,@balajisHe is like batman, will fight crime in any organization, through any means necessary (even unsanctioned methods).",
            "link": "/brian_armstrong/status/1958914464339959998#m"
          },
          "media": [
            {
              "type": "image",
              "src": "/pic/amplify_video_thumb%2F1959003435862564865%2Fimg%2Fjhwx_r4iDIJSj8mC.jpg%3Fname%3Dsmall%26format%3Dwebp",
              "alt": ""
            },
            {
              "type": "video",
              "thumbnail": "/pic/amplify_video_thumb%2F1959003435862564865%2Fimg%2Fjhwx_r4iDIJSj8mC.jpg%3Fname%3Dsmall%26format%3Dwebp"
            }
          ],
          "stats": {},
          "handle": "balajis",
          "importance_score": 8,
          "importance_reason": "High priority keyword (AI not available - using keywords)",
          "ai_provider": "gpt"
        },
        {
          "tweet_url": "/balajis/status/1958284707025883334#m",
          "tweet_id": "1958284707025883334",
          "is_retweet": false,
          "is_pinned": false,
          "author": "Balaji",
          "username": "@balajis",
          "date": "Aug 20",
          "full_date": "Aug 20, 2025 Â· 9:47 PM UTC",
          "text": "What are the largest economies in the world by GDP-PPP?\n\n(1) China ðŸ‡¨ðŸ‡³ \n(2) USA ðŸ‡ºðŸ‡¸ \n(3) India ðŸ‡®ðŸ‡³ \n(4) Russia ðŸ‡·ðŸ‡º \n\nDemocrats fought Russia and Republicans are now antagonizing India. But itâ€™s not particularly smart to fight the RIC of BRICS at the same time.",
          "quoted_tweet": null,
          "media": [
            {
              "type": "image",
              "src": "/pic/media%2FGy05juxaoAA_Ep2.jpg%3Fname%3Dsmall%26format%3Dwebp",
              "alt": ""
            }
          ],
          "stats": {
            "likes": ""
          },
          "handle": "balajis",
          "importance_score": 8,
          "importance_reason": "High priority keyword (AI not available - using keywords)",
          "ai_provider": "gpt"
        },
        {
          "tweet_url": "/balajis/status/1958218168499057115#m",
          "tweet_id": "1958218168499057115",
          "is_retweet": false,
          "is_pinned": false,
          "author": "Balaji",
          "username": "@balajis",
          "date": "Aug 20",
          "full_date": "Aug 20, 2025 Â· 5:22 PM UTC",
          "text": "TRADEOFFS DO EXIST\n\nSeveral things are true at the same time.\n\n(1) First, woke is cancer, and US universities are one of the primary sources of this cancer. They are the furthest left organizations in the world, and still radically out of sync with the people who fund them. This just came out in Nature:\n\n(2) So, the use of state power against wokeness is probably the only way to course correct, because academic wokeness is funded by the state. State power could be like chemotherapy against the cancer.\n\n(3) However, just as it is possible for the Western university to die from cancer, it is also possible for the university to die from chemotherapy. Particularly if no distinction is made between healthy and unhealthy tissue.\n\n(4) And the recent academic budget cuts are hitting the relatively healthy STEM part of academia, as opposed to the completely unhealthy humanities part.\n\n(5) Thatâ€™s not to say that STEM hasnâ€™t been corrupted by woke too. It has, particularly in medicine. But there was still some residual healthy tissue, some very smart people doing good things.\n\n(6) One of the worldâ€™s greatest living mathematicians (Terry Tao) was among that healthy tissue. If you read his blog, he really isnâ€™t a far leftist. True, he posted against Trump once in 2016 (but so did much of the current admin). And yes, Tao did sign a letter during the BLM riots of 2020 (but even Trump at the time felt compelled to â€œhonor the memory of George Floyd\").\n\n(7) Remember, the social pressure to fit in at UCLA during BLM was even greater than society at large. Wokes, like communists, demand public pledges of fealty to stop harassing you. That doesnâ€™t mean those public pledges are always deeply felt or sincere. Indeed, it is the relatively apolitical STEM guys like Tao who often go along to get along.\n\n(8) Anyway, if one canâ€™t or wonâ€™t make distinctions between a Terry Tao and a genuinely far left humanities prof, you will lose all the healthy tissue. The chemotherapy will kill the host. And four hundred years of Harvard's rise will come to an end.\n\n(9) That said, to steelman the MAGA side, one can actually make the case that the end of Harvard (and the Western university system writ broadly) actually is net good for the world! After all, US universities exported many bad ideas globally, particularly recently. From the claim that XX/XY chromosomes have no relevance in medicine, to the idea that prestigious citations count for more than independent replication, to the decades of attacks on white people simply for being white.\n\n(10) And, to further steelman the right, it is of course hard and time-consuming to separate the innocent from the guilty among the faculty. Indeed it may not even be possible in the time available, given that MAGA may lose political power in a few years. So perhaps itâ€™s now or never.\n\n(11) Fine. But nature abhors a vacuum. And if you leave a smoking crater where Harvard was, that vacuum will currently get filled by China (with certainty) and perhaps the Internet (if weâ€™re lucky). For example:\n\n(12) Anyway, Iâ€™m sympathetic to both the argument that woke is cancer and needed treatment and the reality that many talented individuals are becoming collateral damage here.\n\n(13) Weâ€™ve seen something similar before. In the early 1900s, Europe was the unquestioned leader in science. But then, after all the fighting between right and left, science left for the stable terrain of America. The graph below quantifies this for the physics Nobel:\n\n(14) History may repeat. In the early 2000s, America was similarly the unquestioned global leader in science. But after all the fighting between right and left, science is digitally decentralizing to the Internet (with professors becoming tech founders) and physically recentralizing in Asia (with China taking over traditional academia):\n\n(15) In other words, tradeoffs do exist. It might still be worth it for MAGA to wreck US academia, to break the source of woke in the few years they have power, regardless of what collateral damage occurs. It'd be an immensely altruistic move, like throwing the one ring into the fires of Mount Doom. MAGA would essentially be saving the world from Western leftism by shutting down all sources of blue power, like the universities and the US dollar, and thereby ending the empire.\n\n(16) It'd be like Gorbachev and the Russians shutting down the USSR, thereby ending the careers of many brilliant Soviet scientists (and Russia's own predominance on the world stage) in the process of shutting down a far left empire.\n\nGorbachev saved the world from communism at the expense of Russian power. MAGA may similarly save the world from wokism at the expense of American power. That may not be what they intend to do, but it is arguably what they're actually doing.",
          "quoted_tweet": {
            "author": "tantum",
            "username": "@QuasLacrimas",
            "date": "Aug 20",
            "text": "I'm not going to say anything moralizing about whether Professor Tao should/shouldn't, will/won't go to Tsinghua.\n\nI'll just say that if an offer like that ever comes, and he accepts it, none of his colleagues at Tsinghua will be attacking Chinese society on race, gender and sexuality grounds. Nor will they be supporting a mass student protest movement that advocates bringing political violence to China. Nor will they be threatening to shut down their research to protest the CCP denying certain foreigners visas for political reasons.\n\nI'm not saying that's good or bad. I'm just saying it will never happen at Tsinghua.\n\nAnyone who is upset that the US government is sanctioning universities for anti-American agendas, and would rather work in China than have his own university follow (pro-American) government guidance, isn't against government control of universities. That would be absurd in the extreme. He would be in favor of very strict government control of universities, students, and faculty, so long as it is a control by a government he feels loyalty to.",
            "link": "/QuasLacrimas/status/1957960430766133563#m"
          },
          "media": [
            {
              "type": "image",
              "src": "/pic/media%2FGyz9Cn3aAAMxSKi.jpg%3Fname%3Dsmall%26format%3Dwebp",
              "alt": ""
            },
            {
              "type": "image",
              "src": "/pic/media%2FGyz2dxlaAAM0OmW.jpg%3Fname%3Dsmall%26format%3Dwebp",
              "alt": ""
            },
            {
              "type": "image",
              "src": "/pic/media%2FGyz45BZbkAAAwE4.png%3Fname%3Dsmall%26format%3Dwebp",
              "alt": ""
            },
            {
              "type": "image",
              "src": "/pic/media%2FGyz53e2aAAE3tov.png%3Fname%3Dsmall%26format%3Dwebp",
              "alt": ""
            }
          ],
          "stats": {},
          "handle": "balajis",
          "importance_score": 8,
          "importance_reason": "High priority keyword (AI not available - using keywords)",
          "ai_provider": "gpt"
        },
        {
          "tweet_url": "/balajis/status/1957740572845961324#m",
          "tweet_id": "1957740572845961324",
          "is_retweet": false,
          "is_pinned": false,
          "author": "Balaji",
          "username": "@balajis",
          "date": "Aug 19",
          "full_date": "Aug 19, 2025 Â· 9:45 AM UTC",
          "text": "Donâ€™t be surprised if China offers Terry Tao the chair of the mathematics department at Tsinghua University.\n\nAnd all the funding he wants.\n\nBecause it is possible for the US to fumble the bag as the destination for global talent. And indeed it is fumbling that bag right now.",
          "quoted_tweet": {
            "author": "Paul Graham",
            "username": "@paulg",
            "date": "Aug 3",
            "text": "The Trump administration has suspended the funding of Terence Tao and the Institute for Pure and Applied Mathematics at UCLA.",
            "link": "/paulg/status/1951996478555357530#m"
          },
          "media": [
            {
              "type": "image",
              "src": "/pic/media%2FGxbiWwcaoAAisK-.png%3Fname%3Dsmall%26format%3Dwebp",
              "alt": ""
            }
          ],
          "stats": {
            "likes": ""
          },
          "handle": "balajis",
          "importance_score": 8,
          "importance_reason": "High priority keyword (AI not available - using keywords)",
          "ai_provider": "gpt"
        },
        {
          "tweet_url": "/balajis/status/1957736491259494842#m",
          "tweet_id": "1957736491259494842",
          "is_retweet": false,
          "is_pinned": false,
          "author": "Balaji",
          "username": "@balajis",
          "date": "Aug 19",
          "full_date": "Aug 19, 2025 Â· 9:28 AM UTC",
          "text": "Itâ€™s extraordinarily difficult to build something like SpaceX even in peacetime.\n\nIf huge swaths of society are irrationally trying to get you, the difficulty rises further by orders of magnitude.\n\nMeanwhile, China just plows ahead relentlessly.",
          "quoted_tweet": {
            "author": "Eric Berger",
            "username": "@SciGuySpace",
            "date": "Aug 18",
            "text": "I went there. Because at this point, it's difficult to come to any other conclusion.arstechnica.com/space/2025/0â€¦",
            "link": "/SciGuySpace/status/1957495041544364338#m"
          },
          "media": [],
          "stats": {},
          "handle": "balajis",
          "importance_score": 7,
          "importance_reason": "Company keyword (AI not available - using keywords)",
          "ai_provider": "gpt"
        }
      ],
      "filtered_out_count": 15,
      "ai_classification_enabled": true,
      "ai_provider": "gpt",
      "handle_config": {
        "min_score": 7,
        "context": "Balaji Srinivasan content (crypto, tech trends, geopolitics, innovation)"
      }
    }
  ],
  "combined_tweets": [
    {
      "tweet_url": "/karpathy/status/1617979122625712128#m",
      "tweet_id": "1617979122625712128",
      "is_retweet": false,
      "is_pinned": true,
      "author": "Andrej Karpathy",
      "username": "@karpathy",
      "date": "24 Jan 2023",
      "full_date": "Jan 24, 2023 Â· 8:14 PM UTC",
      "text": "The hottest new programming language is English",
      "quoted_tweet": null,
      "media": [],
      "stats": {
        "replies": "",
        "retweets": "",
        "quotes": "",
        "likes": ""
      },
      "handle": "karpathy",
      "importance_score": 9,
      "importance_reason": "Pinned tweet (AI not available - using keywords)",
      "ai_provider": "gpt"
    },
    {
      "tweet_url": "/naval/status/1002103360646823936#m",
      "tweet_id": "1002103360646823936",
      "is_retweet": false,
      "is_pinned": true,
      "author": "Naval",
      "username": "@naval",
      "date": "31 May 2018",
      "full_date": "May 31, 2018 Â· 8:23 AM UTC",
      "text": "How to Get Rich (without getting lucky):",
      "quoted_tweet": null,
      "media": [],
      "stats": {
        "replies": "",
        "retweets": "",
        "quotes": "",
        "likes": ""
      },
      "handle": "naval",
      "importance_score": 9,
      "importance_reason": "Pinned tweet (AI not available - using keywords)",
      "ai_provider": "gpt"
    },
    {
      "tweet_url": "/pmarca/status/1902724994607570975#m",
      "tweet_id": "1902724994607570975",
      "is_retweet": false,
      "is_pinned": true,
      "author": "Marc Andreessen ðŸ‡ºðŸ‡¸",
      "username": "@pmarca",
      "date": "Mar 20",
      "full_date": "Mar 20, 2025 Â· 2:12 PM UTC",
      "text": "THAT'S RIGHT.",
      "quoted_tweet": null,
      "media": [
        {
          "type": "image",
          "src": "/pic/ext_tw_video_thumb%2F1902724959589253120%2Fpu%2Fimg%2FEf8KguO1P_C8NyaT.jpg%3Fname%3Dsmall%26format%3Dwebp",
          "alt": ""
        },
        {
          "type": "video",
          "thumbnail": "/pic/ext_tw_video_thumb%2F1902724959589253120%2Fpu%2Fimg%2FEf8KguO1P_C8NyaT.jpg%3Fname%3Dsmall%26format%3Dwebp"
        }
      ],
      "stats": {
        "retweets": "",
        "likes": ""
      },
      "handle": "pmarca",
      "importance_score": 9,
      "importance_reason": "Pinned tweet (AI not available - using keywords)",
      "ai_provider": "gpt"
    },
    {
      "tweet_url": "/balajis/status/1947365217874416120#m",
      "tweet_id": "1947365217874416120",
      "is_retweet": false,
      "is_pinned": true,
      "author": "Balaji",
      "username": "@balajis",
      "date": "Jul 21",
      "full_date": "Jul 21, 2025 Â· 6:37 PM UTC",
      "text": "Come to Singapore on October 3.ns.com/conference2025",
      "quoted_tweet": null,
      "media": [
        {
          "type": "image",
          "src": "/pic/media%2FGwZuBbEbEAIyezg.jpg%3Fname%3Dsmall%26format%3Dwebp",
          "alt": ""
        }
      ],
      "stats": {
        "likes": ""
      },
      "handle": "balajis",
      "importance_score": 9,
      "importance_reason": "Pinned tweet (AI not available - using keywords)",
      "ai_provider": "gpt"
    },
    {
      "tweet_url": "/sama/status/1957849495733166587#m",
      "tweet_id": "1957849495733166587",
      "is_retweet": false,
      "is_pinned": false,
      "author": "Sam Altman",
      "username": "@sama",
      "date": "Aug 19",
      "full_date": "Aug 19, 2025 Â· 4:57 PM UTC",
      "text": "ChatGPT Go launches in India!\n\nLooking forward to making ChatGPT more affordable in India first, and then learning from feedback to expand to other countries.",
      "quoted_tweet": {
        "author": "Nick Turley",
        "username": "@nickaturley",
        "date": "Aug 19",
        "text": "We just launched ChatGPT Go in India, a new subscription tier that gives users in India more access to our most popular features: 10x higher message limits, 10x more image generations, 10x more file uploads, and 2x longer memory compared with our free tier. All for Rs. 399. ðŸ‡®ðŸ‡³",
        "link": "/nickaturley/status/1957613818902892985#m"
      },
      "media": [],
      "stats": {
        "replies": "",
        "retweets": "",
        "likes": ""
      },
      "handle": "sama",
      "importance_score": 8,
      "importance_reason": "High priority keyword (AI not available - using keywords)",
      "ai_provider": "gpt"
    },
    {
      "tweet_url": "/sama/status/1954703747495649670#m",
      "tweet_id": "1954703747495649670",
      "is_retweet": false,
      "is_pinned": false,
      "author": "Sam Altman",
      "username": "@sama",
      "date": "Aug 11",
      "full_date": "Aug 11, 2025 Â· 12:37 AM UTC",
      "text": "If you have been following the GPT-5 rollout, one thing you might be noticing is how much of an attachment some people have to specific AI models. It feels different and stronger than the kinds of attachment people have had to previous kinds of technology (and so suddenly deprecating old models that users depended on in their workflows was a mistake).\n\nThis is something weâ€™ve been closely tracking for the past year or so but still hasnâ€™t gotten much mainstream attention (other than when we released an update to GPT-4o that was too sycophantic).\n\n(This is just my current thinking, and not yet an official OpenAI position.)\n\nPeople have used technology including AI in self-destructive ways; if a user is in a mentally fragile state and prone to delusion, we do not want the AI to reinforce that. Most users can keep a clear line between reality and fiction or role-play, but a small percentage cannot. We value user freedom as a core principle, but we also feel responsible in how we introduce new technology with new risks.\n\nEncouraging delusion in a user that is having trouble telling the difference between reality and fiction is an extreme case and itâ€™s pretty clear what to do, but the concerns that worry me most are more subtle. There are going to be a lot of edge cases, and generally we plan to follow the principle of â€œtreat adult users like adultsâ€, which in some cases will include pushing back on users to ensure they are getting what they really want.\n\nA lot of people effectively use ChatGPT as a sort of therapist or life coach, even if they wouldnâ€™t describe it that way. This can be really good! A lot of people are getting value from it already today.\n\nIf people are getting good advice, leveling up toward their own goals, and their life satisfaction is increasing over years, we will be proud of making something genuinely helpful, even if they use and rely on ChatGPT a lot. If, on the other hand, users have a relationship with ChatGPT where they think they feel better after talking but theyâ€™re unknowingly nudged away from their longer term well-being (however they define it), thatâ€™s bad. Itâ€™s also bad, for example, if a user wants to use ChatGPT less and feels like they cannot.\n\nI can imagine a future where a lot of people really trust ChatGPTâ€™s advice for their most important decisions. Although that could be great, it makes me uneasy. But I expect that it is coming to some degree, and soon billions of people may be talking to an AI in this way. So we (we as in society, but also we as in OpenAI) have to figure out how to make it a big net positive.\n\nThere are several reasons I think we have a good shot at getting this right. We have much better tech to help us measure how we are doing than previous generations of technology had. For example, our product can talk to users to get a sense for how they are doing with their short- and long-term goals, we can explain sophisticated and nuanced issues to our models, and much more.",
      "quoted_tweet": null,
      "media": [],
      "stats": {
        "replies": "",
        "retweets": "",
        "likes": ""
      },
      "handle": "sama",
      "importance_score": 8,
      "importance_reason": "High priority keyword (AI not available - using keywords)",
      "ai_provider": "gpt"
    },
    {
      "tweet_url": "/karpathy/status/1952076108565991588#m",
      "tweet_id": "1952076108565991588",
      "is_retweet": false,
      "is_pinned": false,
      "author": "Andrej Karpathy",
      "username": "@karpathy",
      "date": "Aug 3",
      "full_date": "Aug 3, 2025 Â· 6:36 PM UTC",
      "text": "Shower of thoughts: Instead of keeping your Twitter/ð• payout, direct it towards a \"PayoutChallenge\" of your choosing - anything you want more of in the world!\n\nHere is mine for this round, combining my last 3 payouts of $5478.51:\n\nIt is imperative that humanity not fall while AI ascends. Humanity has to continue to rise, become better alongside. Create something that is specifically designed to uplift team human. Definition intentionally left a bit vague to keep some entropy around people's interpretation, but imo examples include:\n- Any piece of software that aids explanation, visualization, memorization, inspiration, understanding, coordination, etc...\n- It doesn't have to be too lofty, e.g. it can be a specific educational article/video explaining something some other people could benefit from or that you have unique knowledge of.\n- Prompts/agents for explanation, e.g. along the lines of recently released ChatGPT study mode.\n- Related works of art\n\nThis challenge will run for 2 weeks until Aug 17th EOD PST. Submit your contribution as a reply. It has to be something that was uniquely created for this challenge and would not exist otherwise. Criteria includes execution, leverage, novelty, inspiration, aesthetics, amusement. People can upvote submissions by liking, this \"people's choice\" will also be a factor. I will decide the winner on Aug 17th and send $5478.51 :)",
      "quoted_tweet": null,
      "media": [],
      "stats": {
        "likes": ""
      },
      "handle": "karpathy",
      "importance_score": 8,
      "importance_reason": "High priority keyword (AI not available - using keywords)",
      "ai_provider": "gpt"
    },
    {
      "tweet_url": "/karpathy/status/1945979830740435186#m",
      "tweet_id": "1945979830740435186",
      "is_retweet": false,
      "is_pinned": false,
      "author": "Andrej Karpathy",
      "username": "@karpathy",
      "date": "Jul 17",
      "full_date": "Jul 17, 2025 Â· 10:52 PM UTC",
      "text": "Diffusion video models but now - **realtime**!\n\nSimple video filters are real-time but can only do basic re-coloring and styles. Video diffusion models (Veo and friends) are magic, but they take many seconds/minutes to generate. MirageLSD is real-time magic. Unlike simple video filters, diffusion models actually *understand* what they are looking at, so they can style all parts of the feed intelligently (e.g. putting hats on heads, or light sabers into hands, etc.). And they are arbitrarily steerable, e.g. by text prompts.\n\nCustomizable, intelligent video filters unlock many cool ideas over time:\n- transform camera feeds into alternate realities\n- direct and shoot your own movies, acting out scenes with props. Realtime => instant feedback/review.\n- vibe code games around just simple spheres/blocks, then use a real-time diffusion model to texture your game to make it beautiful.\n- style and customize any video feed: games, videos, ... e.g. Skyrim but \"MORE EPIC\"? DOOM II but modern Unreal Engine quality with just a prompt? Horror movie but \"cute, pink and bunnies only\"? I don't know!\n- zoom call backgrounds+++\n- real-time try on clothes virtually\n- glasses: e.g. cartoonify your vision in real time?\n- we can now build Harry Potter Mirror of Erised, showing the \"raw feed\" of you in the mirror but augmented with your deepest desires (as inferred by the AI).\n- I don't know, I'm probably missing the biggest one, so many things!\n\n(Disclosure I am (very small) angel investor in Decart, I was excited because imo this technology will get very good very fast and it feels general, powerful but it's also technically very difficult. Congrats on the launch to the team!)",
      "quoted_tweet": {
        "author": "Decart",
        "username": "@DecartAI",
        "date": "Jul 17",
        "text": "Introducing MirageLSD: The First Live-Stream Diffusion (LSD) AI Model\n\nInput any video stream, from a camera or video chat to a computer screen or game, and transform it into any world you desire, in real-time (<40ms latency).\n\nHereâ€™s how it works (w/ demo you can use!):",
        "link": "/DecartAI/status/1945947692871692667#m"
      },
      "media": [
        {
          "type": "image",
          "src": "/pic/amplify_video_thumb%2F1945947630892470273%2Fimg%2FtMWGyDcoT3KmQg0U.jpg%3Fname%3Dsmall%26format%3Dwebp",
          "alt": ""
        },
        {
          "type": "video",
          "thumbnail": "/pic/amplify_video_thumb%2F1945947630892470273%2Fimg%2FtMWGyDcoT3KmQg0U.jpg%3Fname%3Dsmall%26format%3Dwebp"
        }
      ],
      "stats": {
        "likes": ""
      },
      "handle": "karpathy",
      "importance_score": 8,
      "importance_reason": "High priority keyword (AI not available - using keywords)",
      "ai_provider": "gpt"
    },
    {
      "tweet_url": "/karpathy/status/1940181840201228384#m",
      "tweet_id": "1940181840201228384",
      "is_retweet": false,
      "is_pinned": false,
      "author": "Andrej Karpathy",
      "username": "@karpathy",
      "date": "Jul 1",
      "full_date": "Jul 1, 2025 Â· 10:52 PM UTC",
      "text": "Test-based certification is the only way forward in food, eager to see more over time.\n\nFood is not simple anymore - it is a complex, industrial product with global supply and processing chains. Contamination can be introduced in many stages along the way from farming to harvest, processing, packaging, transport and preparation. Examples include pesticides, nitrates, heavy metals, plastics, bacteria, etc etc. So it's not just about what food to eat, it's about which specific food item SKU, from which specific supplier, and the only way to know is to test. E.g. these two cat foods look the same, the ingredients might look the same, but the one on the left is 1000X higher in glyphosate and 100X in lead. Or e.g. this baby food formula or turmeric is loaded with heavy metals, this canned seafood, your local boba or this milk brand is seeped in plastics, or this breakfast cereal way way too high in glyphosate (real examples).\n\nI used to think that the FDA exercises oversight but the reality is that it doesn't have anywhere near enough resources to do it thoroughly and their focus is a lot more on e.g. acute microbial threats (like Salmonella, E. coli, Listeria, ...) that immediately hospitalize people, less on the rapidly growing diversity of compounds that may or may not deteriorate health over decades and that are basically treated as innocent until proven guilty under GRAS and so on. Meanwhile, the public health macro picture looks not so great - obesity up, type-2 diabetes up, fertility down (sperm count/motility), weird endocrine trends (e.g. testosterone down in men), depression and anxiety up... It wouldn't shock me if modern industrial food turns out to be a major contributor.",
      "quoted_tweet": {
        "author": "Bryan Johnson",
        "username": "@bryan_johnson",
        "date": "Jul 1",
        "text": "Something new and exciting is here\n\nDog and cat food toxin testing\n+ fund your pet's food\n+ if brand claims results, your money comes back \n+ fund more tests\n\nTogether we can rapidly test all US dog and cat food. \n\nInitial results \nBlueprint Quantified tested 22 mass-market products (12 dog foods, 10 cat foods) from 14 US national brands. \n\nGlyphosate\n+ Detected in 21 of 22 products (95%).\n+ 8 products hit the upper detection limit of 1,000 ppm\n+ Thatâ€™s 118 mg glyphosate in a 118 g serving, equivalent to maximum tolerable exposure for 68 kg human \n+ Lowest non-zero hit: 0.04 ppm (Merrick Chicken & Sweet Potato)\n\nHeavy metals\n+ mercury, lead, arsenic, and cadmium were detected in every sample\n+ arsenic: up to 0.238 ppm / 238 ppb (Sheba Seafood Wet Cat Food). 8.9 mcg per 38 g serving\n+ cadmium: up to 0.084 ppm / 83.6 ppb (Royal Canin Medium Adult Dog).\n+ lead: up to 0.343 ppm / 343 ppb (Royal Canin Indoor Adult Cat), 12.9 mcg of lead per 38 g servingÂ  (26x California Prop 65â€™s daily limit (0.5 mcg))\n+ mercury: up to 0.012 ppm / 11.8 ppb (Sheba Seafood Wet Cat Food)\n\nTop heavy metal toxicity:\n+ Wellness CORE+ Original (Dog): 43.4 Âµg/serving\n+ Nutro Natural Choice Small Breed (Dog): 42.6 Âµg/serving\n+ Blue Buffalo Homestyle Senior (Dog, wet): 35.6 Âµg/serving\n+ Royal Canin Size Health Medium Dog: 33.7 Âµg/serving\n+ Pedigree Small Dog â€œGrilled Steak & Vegâ€ (Dog): 27.9 Âµg Âµg/serving\n\nCleanest product\nPurina Friskies Surfinâ€™ & Turfinâ€™ (Cat) had non-detectable glyphosate, and the second lowest total heavy metals.",
        "link": "/bryan_johnson/status/1940112033493786979#m"
      },
      "media": [
        {
          "type": "image",
          "src": "/pic/media%2FGuym1p0XIAAfMzh.jpg%3Fname%3Dsmall%26format%3Dwebp",
          "alt": ""
        }
      ],
      "stats": {
        "likes": ""
      },
      "handle": "karpathy",
      "importance_score": 8,
      "importance_reason": "High priority keyword (AI not available - using keywords)",
      "ai_provider": "gpt"
    },
    {
      "tweet_url": "/naval/status/1952519682256466329#m",
      "tweet_id": "1952519682256466329",
      "is_retweet": false,
      "is_pinned": false,
      "author": "Naval",
      "username": "@naval",
      "date": "Aug 4",
      "full_date": "Aug 4, 2025 Â· 11:59 PM UTC",
      "text": "nav.al/hiringNivi: Weâ€™re hiring an editor for the Naval Podcast, and Naval is also hiring a chief of staff. If youâ€™re not interested in either of these, you can move on to the next episode. Let me give you some details on both of them.\n\nFirst, the editor for the Naval Podcast, which as you already know, is the most timeless and overproduced podcast in human history. The editor will be primarily editing the podcast in Descript. Theyâ€™ll be editing the transcripts for clarity and posting videos to social media to get Navalâ€™s ideas into the hands of 8 billion people on planet Earth. If youâ€™re already working on another podcast, donâ€™t hesitate to contact us. Youâ€™ll learn more with us.\n\nIf youâ€™re more of a producer than an editor, feel free to get in touch anyway. We are open to new ideas. This is a part-time role, but thereâ€™s infinite room to get into more challenging and creative problems. You donâ€™t need experience, but you need to be extremely smart and high-slope. Hereâ€™s some more details on what weâ€™re looking for.\n\nYou must have a DSM-5 level attention to detail. You must be a good writer with a nose for design, and you must get things the first time you hear them. Please send less than 750 characters about yourself to podcast@nav.al. Include links to your best work and your smartest tweet. Tell us about a hard problem youâ€™ve solved, new knowledge youâ€™re creating for fun, and share something youâ€™ve made with AI. The shorter your email, the better. \n\nThanks for considering us.\n\nChief of Staff\n\nOn to the second position. Naval is also hiring a chief of staff to work directly with him. This is independent of the podcast. Youâ€™ll be working with him to solve problems, including traveling the world to recruit engineers, researching investments, throwing events, personal tasks, and anything else he needs done.\n\nThe work will range from prestigious to pauperian. You must be extremely technical, always working, based in San Francisco and willing to travel anytime. The right person probably has a couple years of work under their belt and wants to start a company one day. Again, please send under 750 characters about yourself to chief@nav.al.\n\nInclude links to your best work and your smartest tweet. Tell us about a hard problem youâ€™ve solved, new knowledge youâ€™re creating for fun, and share something youâ€™ve made with AI. The shorter your message, the better.\n\nThanks for considering this.",
      "quoted_tweet": null,
      "media": [],
      "stats": {},
      "handle": "naval",
      "importance_score": 8,
      "importance_reason": "High priority keyword (AI not available - using keywords)",
      "ai_provider": "gpt"
    },
    {
      "tweet_url": "/brian_armstrong/status/1959003696693748055#m",
      "tweet_id": "1959003696693748055",
      "is_retweet": true,
      "retweet_info": "Balaji retweeted",
      "is_pinned": false,
      "author": "Brian Armstrong",
      "username": "@brian_armstrong",
      "date": "2h",
      "full_date": "Aug 22, 2025 Â· 9:24 PM UTC",
      "text": "Fun fact: as CTO Balaji was the person most responsible for driving the launch of USDC on the Coinbase side.\n\nHere's the launch video:",
      "quoted_tweet": {
        "author": "Brian Armstrong",
        "username": "@brian_armstrong",
        "date": "8h",
        "text": "The one and only, legendary,@balajisHe is like batman, will fight crime in any organization, through any means necessary (even unsanctioned methods).",
        "link": "/brian_armstrong/status/1958914464339959998#m"
      },
      "media": [
        {
          "type": "image",
          "src": "/pic/amplify_video_thumb%2F1959003435862564865%2Fimg%2Fjhwx_r4iDIJSj8mC.jpg%3Fname%3Dsmall%26format%3Dwebp",
          "alt": ""
        },
        {
          "type": "video",
          "thumbnail": "/pic/amplify_video_thumb%2F1959003435862564865%2Fimg%2Fjhwx_r4iDIJSj8mC.jpg%3Fname%3Dsmall%26format%3Dwebp"
        }
      ],
      "stats": {},
      "handle": "balajis",
      "importance_score": 8,
      "importance_reason": "High priority keyword (AI not available - using keywords)",
      "ai_provider": "gpt"
    },
    {
      "tweet_url": "/balajis/status/1958284707025883334#m",
      "tweet_id": "1958284707025883334",
      "is_retweet": false,
      "is_pinned": false,
      "author": "Balaji",
      "username": "@balajis",
      "date": "Aug 20",
      "full_date": "Aug 20, 2025 Â· 9:47 PM UTC",
      "text": "What are the largest economies in the world by GDP-PPP?\n\n(1) China ðŸ‡¨ðŸ‡³ \n(2) USA ðŸ‡ºðŸ‡¸ \n(3) India ðŸ‡®ðŸ‡³ \n(4) Russia ðŸ‡·ðŸ‡º \n\nDemocrats fought Russia and Republicans are now antagonizing India. But itâ€™s not particularly smart to fight the RIC of BRICS at the same time.",
      "quoted_tweet": null,
      "media": [
        {
          "type": "image",
          "src": "/pic/media%2FGy05juxaoAA_Ep2.jpg%3Fname%3Dsmall%26format%3Dwebp",
          "alt": ""
        }
      ],
      "stats": {
        "likes": ""
      },
      "handle": "balajis",
      "importance_score": 8,
      "importance_reason": "High priority keyword (AI not available - using keywords)",
      "ai_provider": "gpt"
    },
    {
      "tweet_url": "/balajis/status/1958218168499057115#m",
      "tweet_id": "1958218168499057115",
      "is_retweet": false,
      "is_pinned": false,
      "author": "Balaji",
      "username": "@balajis",
      "date": "Aug 20",
      "full_date": "Aug 20, 2025 Â· 5:22 PM UTC",
      "text": "TRADEOFFS DO EXIST\n\nSeveral things are true at the same time.\n\n(1) First, woke is cancer, and US universities are one of the primary sources of this cancer. They are the furthest left organizations in the world, and still radically out of sync with the people who fund them. This just came out in Nature:\n\n(2) So, the use of state power against wokeness is probably the only way to course correct, because academic wokeness is funded by the state. State power could be like chemotherapy against the cancer.\n\n(3) However, just as it is possible for the Western university to die from cancer, it is also possible for the university to die from chemotherapy. Particularly if no distinction is made between healthy and unhealthy tissue.\n\n(4) And the recent academic budget cuts are hitting the relatively healthy STEM part of academia, as opposed to the completely unhealthy humanities part.\n\n(5) Thatâ€™s not to say that STEM hasnâ€™t been corrupted by woke too. It has, particularly in medicine. But there was still some residual healthy tissue, some very smart people doing good things.\n\n(6) One of the worldâ€™s greatest living mathematicians (Terry Tao) was among that healthy tissue. If you read his blog, he really isnâ€™t a far leftist. True, he posted against Trump once in 2016 (but so did much of the current admin). And yes, Tao did sign a letter during the BLM riots of 2020 (but even Trump at the time felt compelled to â€œhonor the memory of George Floyd\").\n\n(7) Remember, the social pressure to fit in at UCLA during BLM was even greater than society at large. Wokes, like communists, demand public pledges of fealty to stop harassing you. That doesnâ€™t mean those public pledges are always deeply felt or sincere. Indeed, it is the relatively apolitical STEM guys like Tao who often go along to get along.\n\n(8) Anyway, if one canâ€™t or wonâ€™t make distinctions between a Terry Tao and a genuinely far left humanities prof, you will lose all the healthy tissue. The chemotherapy will kill the host. And four hundred years of Harvard's rise will come to an end.\n\n(9) That said, to steelman the MAGA side, one can actually make the case that the end of Harvard (and the Western university system writ broadly) actually is net good for the world! After all, US universities exported many bad ideas globally, particularly recently. From the claim that XX/XY chromosomes have no relevance in medicine, to the idea that prestigious citations count for more than independent replication, to the decades of attacks on white people simply for being white.\n\n(10) And, to further steelman the right, it is of course hard and time-consuming to separate the innocent from the guilty among the faculty. Indeed it may not even be possible in the time available, given that MAGA may lose political power in a few years. So perhaps itâ€™s now or never.\n\n(11) Fine. But nature abhors a vacuum. And if you leave a smoking crater where Harvard was, that vacuum will currently get filled by China (with certainty) and perhaps the Internet (if weâ€™re lucky). For example:\n\n(12) Anyway, Iâ€™m sympathetic to both the argument that woke is cancer and needed treatment and the reality that many talented individuals are becoming collateral damage here.\n\n(13) Weâ€™ve seen something similar before. In the early 1900s, Europe was the unquestioned leader in science. But then, after all the fighting between right and left, science left for the stable terrain of America. The graph below quantifies this for the physics Nobel:\n\n(14) History may repeat. In the early 2000s, America was similarly the unquestioned global leader in science. But after all the fighting between right and left, science is digitally decentralizing to the Internet (with professors becoming tech founders) and physically recentralizing in Asia (with China taking over traditional academia):\n\n(15) In other words, tradeoffs do exist. It might still be worth it for MAGA to wreck US academia, to break the source of woke in the few years they have power, regardless of what collateral damage occurs. It'd be an immensely altruistic move, like throwing the one ring into the fires of Mount Doom. MAGA would essentially be saving the world from Western leftism by shutting down all sources of blue power, like the universities and the US dollar, and thereby ending the empire.\n\n(16) It'd be like Gorbachev and the Russians shutting down the USSR, thereby ending the careers of many brilliant Soviet scientists (and Russia's own predominance on the world stage) in the process of shutting down a far left empire.\n\nGorbachev saved the world from communism at the expense of Russian power. MAGA may similarly save the world from wokism at the expense of American power. That may not be what they intend to do, but it is arguably what they're actually doing.",
      "quoted_tweet": {
        "author": "tantum",
        "username": "@QuasLacrimas",
        "date": "Aug 20",
        "text": "I'm not going to say anything moralizing about whether Professor Tao should/shouldn't, will/won't go to Tsinghua.\n\nI'll just say that if an offer like that ever comes, and he accepts it, none of his colleagues at Tsinghua will be attacking Chinese society on race, gender and sexuality grounds. Nor will they be supporting a mass student protest movement that advocates bringing political violence to China. Nor will they be threatening to shut down their research to protest the CCP denying certain foreigners visas for political reasons.\n\nI'm not saying that's good or bad. I'm just saying it will never happen at Tsinghua.\n\nAnyone who is upset that the US government is sanctioning universities for anti-American agendas, and would rather work in China than have his own university follow (pro-American) government guidance, isn't against government control of universities. That would be absurd in the extreme. He would be in favor of very strict government control of universities, students, and faculty, so long as it is a control by a government he feels loyalty to.",
        "link": "/QuasLacrimas/status/1957960430766133563#m"
      },
      "media": [
        {
          "type": "image",
          "src": "/pic/media%2FGyz9Cn3aAAMxSKi.jpg%3Fname%3Dsmall%26format%3Dwebp",
          "alt": ""
        },
        {
          "type": "image",
          "src": "/pic/media%2FGyz2dxlaAAM0OmW.jpg%3Fname%3Dsmall%26format%3Dwebp",
          "alt": ""
        },
        {
          "type": "image",
          "src": "/pic/media%2FGyz45BZbkAAAwE4.png%3Fname%3Dsmall%26format%3Dwebp",
          "alt": ""
        },
        {
          "type": "image",
          "src": "/pic/media%2FGyz53e2aAAE3tov.png%3Fname%3Dsmall%26format%3Dwebp",
          "alt": ""
        }
      ],
      "stats": {},
      "handle": "balajis",
      "importance_score": 8,
      "importance_reason": "High priority keyword (AI not available - using keywords)",
      "ai_provider": "gpt"
    },
    {
      "tweet_url": "/balajis/status/1957740572845961324#m",
      "tweet_id": "1957740572845961324",
      "is_retweet": false,
      "is_pinned": false,
      "author": "Balaji",
      "username": "@balajis",
      "date": "Aug 19",
      "full_date": "Aug 19, 2025 Â· 9:45 AM UTC",
      "text": "Donâ€™t be surprised if China offers Terry Tao the chair of the mathematics department at Tsinghua University.\n\nAnd all the funding he wants.\n\nBecause it is possible for the US to fumble the bag as the destination for global talent. And indeed it is fumbling that bag right now.",
      "quoted_tweet": {
        "author": "Paul Graham",
        "username": "@paulg",
        "date": "Aug 3",
        "text": "The Trump administration has suspended the funding of Terence Tao and the Institute for Pure and Applied Mathematics at UCLA.",
        "link": "/paulg/status/1951996478555357530#m"
      },
      "media": [
        {
          "type": "image",
          "src": "/pic/media%2FGxbiWwcaoAAisK-.png%3Fname%3Dsmall%26format%3Dwebp",
          "alt": ""
        }
      ],
      "stats": {
        "likes": ""
      },
      "handle": "balajis",
      "importance_score": 8,
      "importance_reason": "High priority keyword (AI not available - using keywords)",
      "ai_provider": "gpt"
    },
    {
      "tweet_url": "/sama/status/1955095125597753567#m",
      "tweet_id": "1955095125597753567",
      "is_retweet": false,
      "is_pinned": false,
      "author": "Sam Altman",
      "username": "@sama",
      "date": "Aug 12",
      "full_date": "Aug 12, 2025 Â· 2:32 AM UTC",
      "text": "I hope someone will get counter-discovery on this, I and many others would love to know what's been happening.\n\nBut OpenAI will just stay focused on making great products.",
      "quoted_tweet": null,
      "media": [],
      "stats": {
        "likes": ""
      },
      "handle": "sama",
      "importance_score": 7,
      "importance_reason": "Company keyword (AI not available - using keywords)",
      "ai_provider": "gpt"
    },
    {
      "tweet_url": "/karpathy/status/1944435412489171119#m",
      "tweet_id": "1944435412489171119",
      "is_retweet": false,
      "is_pinned": false,
      "author": "Andrej Karpathy",
      "username": "@karpathy",
      "date": "Jul 13",
      "full_date": "Jul 13, 2025 Â· 4:35 PM UTC",
      "text": "Scaling up RL is all the rage right now, I had a chat with a friend about it yesterday. I'm fairly certain RL will continue to yield more intermediate gains, but I also don't expect it to be the full story. RL is basically \"hey this happened to go well (/poorly), let me slightly increase (/decrease) the probability of every action I took for the future\". You get a lot more leverage from verifier functions than explicit supervision, this is great. But first, it looks suspicious asymptotically - once the tasks grow to be minutes/hours of interaction long, you're really going to do all that work just to learn a single scalar outcome at the very end, to directly weight the gradient? Beyond asymptotics and second, this doesn't feel like the human mechanism of improvement for majority of intelligence tasks. There's significantly more bits of supervision we extract per rollout via a review/reflect stage along the lines of \"what went well? what didn't go so well? what should I try next time?\" etc. and the lessons from this stage feel explicit, like a new string to be added to the system prompt for the future, optionally to be distilled into weights (/intuition) later a bit like sleep. In English, we say something becomes \"second nature\" via this process, and we're missing learning paradigms like this. The new Memory feature is maybe a primordial version of this in ChatGPT, though it is only used for customization not problem solving. Notice that there is no equivalent of this for e.g. Atari RL because there are no LLMs and no in-context learning in those domains. \n\nExample algorithm: given a task, do a few rollouts, stuff them all into one context window (along with the reward in each case), use a meta-prompt to review/reflect on what went well or not to obtain string \"lesson\", to be added to system prompt (or more generally modify the current lessons database). Many blanks to fill in, many tweaks possible, not obvious.\n\nExample of lesson: we know LLMs can't super easily see letters due to tokenization and can't super easily count inside the residual stream, hence 'r' in 'strawberry' being famously difficult. Claude system prompt had a \"quick fix\" patch - a string was added along the lines of \"If the user asks you to count letters, first separate them by commas and increment an explicit counter each time and do the task like that\". This string is the \"lesson\", explicitly instructing the model how to complete the counting task, except the question is how this might fall out from agentic practice, instead of it being hard-coded by an engineer, how can this be generalized, and how lessons can be distilled over time to not bloat context windows indefinitely.\n\nTLDR: RL will lead to more gains because when done well, it is a lot more leveraged, bitter-lesson-pilled, and superior to SFT. It doesn't feel like the full story, especially as rollout lengths continue to expand. There are more S curves to find beyond, possibly specific to LLMs and without analogues in game/robotics-like environments, which is exciting.",
      "quoted_tweet": null,
      "media": [],
      "stats": {
        "likes": ""
      },
      "handle": "karpathy",
      "importance_score": 7,
      "importance_reason": "Company keyword (AI not available - using keywords)",
      "ai_provider": "gpt"
    },
    {
      "tweet_url": "/karpathy/status/1941616674094170287#m",
      "tweet_id": "1941616674094170287",
      "is_retweet": false,
      "is_pinned": false,
      "author": "Andrej Karpathy",
      "username": "@karpathy",
      "date": "Jul 5",
      "full_date": "Jul 5, 2025 Â· 9:54 PM UTC",
      "text": "How to build a thriving open source community by writing code like bacteria do ðŸ¦ . Bacterial code (genomes) are:\n\n- small (each line of code costs energy)\n- modular (organized into groups of swappable operons)\n- self-contained (easily \"copy paste-able\" via horizontal gene transfer)\n\nIf chunks of code are small, modular, self-contained and trivial to copy-and-paste, the community can thrive via horizontal gene transfer. For any function (gene) or class (operon) that you write: can you imagine someone going \"yoink\" without knowing the rest of your code or having to import anything new, to gain a benefit? Could your code be a trending GitHub gist?\n\nThis coding style guide has allowed bacteria to colonize every ecological nook from cold to hot to acidic or alkaline in the depths of the Earth and the vacuum of space, along with an insane diversity of carbon anabolism, energy metabolism, etc. It excels at rapid prototyping but... it can't build complex life. By comparison, the eukaryotic genome is a significantly larger, more complex, organized and coupled monorepo. Significantly less inventive but necessary for complex life - for building entire organs and coordinating their activity. With our advantage of intelligent design, it should possible to take advantage of both. Build a eukaryotic monorepo backbone if you have to, but maximize bacterial DNA.",
      "quoted_tweet": null,
      "media": [
        {
          "type": "image",
          "src": "/pic/media%2FGvIB64XWYAAg1B8.jpg%3Fname%3Dsmall%26format%3Dwebp",
          "alt": ""
        }
      ],
      "stats": {
        "retweets": "",
        "likes": ""
      },
      "handle": "karpathy",
      "importance_score": 7,
      "importance_reason": "Company keyword (AI not available - using keywords)",
      "ai_provider": "gpt"
    },
    {
      "tweet_url": "/balajis/status/1957736491259494842#m",
      "tweet_id": "1957736491259494842",
      "is_retweet": false,
      "is_pinned": false,
      "author": "Balaji",
      "username": "@balajis",
      "date": "Aug 19",
      "full_date": "Aug 19, 2025 Â· 9:28 AM UTC",
      "text": "Itâ€™s extraordinarily difficult to build something like SpaceX even in peacetime.\n\nIf huge swaths of society are irrationally trying to get you, the difficulty rises further by orders of magnitude.\n\nMeanwhile, China just plows ahead relentlessly.",
      "quoted_tweet": {
        "author": "Eric Berger",
        "username": "@SciGuySpace",
        "date": "Aug 18",
        "text": "I went there. Because at this point, it's difficult to come to any other conclusion.arstechnica.com/space/2025/0â€¦",
        "link": "/SciGuySpace/status/1957495041544364338#m"
      },
      "media": [],
      "stats": {},
      "handle": "balajis",
      "importance_score": 7,
      "importance_reason": "Company keyword (AI not available - using keywords)",
      "ai_provider": "gpt"
    },
    {
      "tweet_url": "/karpathy/status/1957574489358873054#m",
      "tweet_id": "1957574489358873054",
      "is_retweet": false,
      "is_pinned": false,
      "author": "Andrej Karpathy",
      "username": "@karpathy",
      "date": "Aug 18",
      "full_date": "Aug 18, 2025 Â· 10:45 PM UTC",
      "text": "I get ~10 spam calls per day (various automated voicemails, \"loan pre-approval\" etc) and ~5 spam messages per day (usually phishing).\n\n- I have AT&T Active Armor, all of the above still slips through.\n- All of the above is always from new, unique numbers so blocking doesn't work.\n- I am on all Do Not Call lists.\n- I have iOS \"Silence Unknown Callers\" on, but even if it catches & silences them I still get the notifications.\n\nNot sure if other people are seeing something similar or figured out anything that works",
      "quoted_tweet": null,
      "media": [],
      "stats": {
        "replies": "",
        "likes": ""
      },
      "handle": "karpathy",
      "importance_score": 6,
      "importance_reason": "Tech keyword (AI not available - using keywords)",
      "ai_provider": "gpt"
    },
    {
      "tweet_url": "/karpathy/status/1957561075744010253#m",
      "tweet_id": "1957561075744010253",
      "is_retweet": false,
      "is_pinned": false,
      "author": "Andrej Karpathy",
      "username": "@karpathy",
      "date": "Aug 18",
      "full_date": "Aug 18, 2025 Â· 9:51 PM UTC",
      "text": "Ok, spent an ~hour sifting through submissions. The biggest challenge was the spam, as majority of replies are people linking to their own existing projects, not things made for the challenge. Of the ones that were:\n\nWinner: I most enjoyed this one from@uncertainsys- OmegaQuest. He's solving Humanity's Last Exam problems with heavy AI use in the loop on video. Actually I really identified with the long pauses and general confusion in trying to use the current state of the art systems in learning something hard and new, where they are simultaneously so tantalizingly helpful at the margins, but still really poor overall, compared to an imagined human expert tutor. The \"explanations\" are... not. But I love the tenacity on display in working out something hard and seeing how far you can get with AI. A good reminder how it's better than what was, but also so far from what could be.nitter.net/uncertainsys/status/19â€¦Shoutout to@measure_planfor cool \"visual vibe coding\" projects, e.g. new musical instrumentsnitter.net/measure_plan/status/19â€¦A few of people commented that the challenge shouldn't have to be only for projects uniquely made for the challenge. If that were the case then shoutout to@evanliinet al. who linked to tinytpu, i really like the animated diagram, i haven't seen that before.nitter.net/evanliin/status/195749â€¦Shoutout to@ChrisChipMonkfor partially incepting the experiment a while ago withnitter.net/ChrisChipMonk/status/1â€¦but I basically come out agreeing with@nearcyanin his earlier commentnitter.net/nearcyan/status/193839â€¦, maybe even $5K isn't :)",
      "quoted_tweet": null,
      "media": [],
      "stats": {},
      "handle": "karpathy",
      "importance_score": 6,
      "importance_reason": "Tech keyword (AI not available - using keywords)",
      "ai_provider": "gpt"
    },
    {
      "tweet_url": "/karpathy/status/1956765908078387382#m",
      "tweet_id": "1956765908078387382",
      "is_retweet": false,
      "is_pinned": false,
      "author": "Andrej Karpathy",
      "username": "@karpathy",
      "date": "Aug 16",
      "full_date": "Aug 16, 2025 Â· 5:12 PM UTC",
      "text": "I am (slowly) re-reading the Tolkien legendarium (of which Lord of the Rings is a small part). The whole body of work is so incredible and there's nothing else like it... it dilutes other worlds of fiction. Wait - your story doesn't have a comprehensive history/mythology spanning multiple ages all the way back to a creation myth as detailed in separate volumes? You didn't first invent new languages and dialects for your characters? You didn't pack it with powerful themes and stories written it in a beautiful, archaic style and compose poems and songs alongside? It didn't take you multiple decades of iteration? And what of all the uncharted territory still remaining? Is Tom Bombadil one of the Ainur. Where are the Entwives. What happened to the two unaccounted Istari. Can we hear more about what it was like in CuiviÃ©nen when the elves first awoke? Or to see the light of the two trees of Valinor. Or of the splendor of the caves of Aglarond.\n\nWhat's most on my mind though - the Tolkien legendarium is imo a concrete example of a height of culture. Does AI, today or soon, make it easier to reach this high via empowerment in both writing and ideation? Or harder, when quick wins are tempting and ~free, and an independent ability to create is stifled. If such a body of work is made again but now with heavy AI assistance, does it inspire the same wonder? What if thousands of them come out on demand with just a prompt? Why do you feel cheated when you learn that something your read was AI generated? Is it transient or a function of capability? Is it slop? What is slop? Or is wonder inseparable from its own creation myth of a lifelong obsession of a mind like your own? So many questions.",
      "quoted_tweet": null,
      "media": [],
      "stats": {
        "replies": "",
        "retweets": "",
        "likes": ""
      },
      "handle": "karpathy",
      "importance_score": 6,
      "importance_reason": "Tech keyword (AI not available - using keywords)",
      "ai_provider": "gpt"
    },
    {
      "tweet_url": "/karpathy/status/1954224651443544436#m",
      "tweet_id": "1954224651443544436",
      "is_retweet": false,
      "is_pinned": false,
      "author": "Andrej Karpathy",
      "username": "@karpathy",
      "date": "Aug 9",
      "full_date": "Aug 9, 2025 Â· 4:53 PM UTC",
      "text": "I'm noticing that due to (I think?) a lot of benchmarkmaxxing on long horizon tasks, LLMs are becoming a little too agentic by default, a little beyond my average use case.\n\nFor example in coding, the models now tend to reason for a fairly long time, they have an inclination to start listing and grepping files all across the entire repo, they do repeated web searchers, they over-analyze and over-think little rare edge cases even in code that is knowingly incomplete and under active development, and often come back ~minutes later even for simple queries.\n\nThis might make sense for long-running tasks but it's less of a good fit for more \"in the loop\" iterated development that I still do a lot of, or if I'm just looking for a quick spot check before running a script, just in case I got some indexing wrong or made some dumb error. So I find myself quite often stopping the LLMs with variations of \"Stop, you're way overthinking this. Look at only this single file. Do not use any tools. Do not over-engineer\", etc.\n\nBasically as the default starts to slowly creep into the \"ultrathink\" super agentic mode, I feel a need for the reverse, and more generally good ways to indicate or communicate intent / stakes, from \"just have a quick look\" all the way to \"go off for 30 minutes, come back when absolutely certain\".",
      "quoted_tweet": null,
      "media": [],
      "stats": {
        "likes": ""
      },
      "handle": "karpathy",
      "importance_score": 6,
      "importance_reason": "Tech keyword (AI not available - using keywords)",
      "ai_provider": "gpt"
    },
    {
      "tweet_url": "/karpathy/status/1946745524033593739#m",
      "tweet_id": "1946745524033593739",
      "is_retweet": false,
      "is_pinned": false,
      "author": "Andrej Karpathy",
      "username": "@karpathy",
      "date": "Jul 20",
      "full_date": "Jul 20, 2025 Â· 1:34 AM UTC",
      "text": "Hi@gmaildoes the \"report phishing\" button do anything",
      "quoted_tweet": null,
      "media": [
        {
          "type": "image",
          "src": "/pic/media%2FGwQ6gB4X0AEFbUy.jpg%3Fname%3Dsmall%26format%3Dwebp",
          "alt": ""
        }
      ],
      "stats": {
        "likes": ""
      },
      "handle": "karpathy",
      "importance_score": 6,
      "importance_reason": "Tech keyword (AI not available - using keywords)",
      "ai_provider": "gpt"
    },
    {
      "tweet_url": "/karpathy/status/1946325810618700033#m",
      "tweet_id": "1946325810618700033",
      "is_retweet": false,
      "is_pinned": false,
      "author": "Andrej Karpathy",
      "username": "@karpathy",
      "date": "Jul 18",
      "full_date": "Jul 18, 2025 Â· 9:46 PM UTC",
      "text": "\"Using a better model for analysis\" ðŸ¤¨\nI didn't realize I was using haiku all this time, no idea when claude code snuck this one in rofl.",
      "quoted_tweet": null,
      "media": [
        {
          "type": "image",
          "src": "/pic/media%2FGwK7Mq_XYAA1W0x.jpg%3Fname%3Dsmall%26format%3Dwebp",
          "alt": ""
        }
      ],
      "stats": {
        "likes": ""
      },
      "handle": "karpathy",
      "importance_score": 6,
      "importance_reason": "Tech keyword (AI not available - using keywords)",
      "ai_provider": "gpt"
    },
    {
      "tweet_url": "/karpathy/status/1943411187296686448#m",
      "tweet_id": "1943411187296686448",
      "is_retweet": false,
      "is_pinned": false,
      "author": "Andrej Karpathy",
      "username": "@karpathy",
      "date": "Jul 10",
      "full_date": "Jul 10, 2025 Â· 8:45 PM UTC",
      "text": "I often rant about how 99% of attention is about to be LLM attention instead of human attention. What does a research paper look like for an LLM instead of a human? Itâ€™s definitely not a pdf. There is huge space for an extremely valuable â€œresearch appâ€ that figures this out.",
      "quoted_tweet": {
        "author": "Michael Levin",
        "username": "@drmichaellevin",
        "date": "Jul 10",
        "text": "I'm constantly irritated that I don't have time to read the torrent of cool papers coming faster and faster from amazing people in relevant fields.  Other scientists have the same issue and have no time to read most of my lengthy conceptual papers either.  So whom are we writing these papers for?\n\nI guess, at least until they fall in to the same issue from their own work, AI's will be the only ones who actually have the bandwidth to read all this stuff.  I'm not specifically talking about today's language models - let's assume we mean whatever inevitable AI shows up, that is able to read the literature and have impact on the research (whether by talking to humans or by running lab automation/robot scientist platforms).\n\nSo then: how should we be writing, knowing that a lot of our audience will be AI (plus cyborgs, hybrots, augmented humans, etc.)?  Maybe it's too early to know what to do, but we better start thinking about it because assuming our audience will always be today's humans seems untenable. Taking seriously the idea that someday the impactful audience will be very different, and that the things we write now are in some sense a training set for truly diverse future beings, how does our writing change? or does it?\n\nwhat say you@danfaggella@mpshanahan@Plinz@blaiseaguera?",
        "link": "/drmichaellevin/status/1943321140128030753#m"
      },
      "media": [],
      "stats": {
        "likes": ""
      },
      "handle": "karpathy",
      "importance_score": 6,
      "importance_reason": "Tech keyword (AI not available - using keywords)",
      "ai_provider": "gpt"
    }
  ],
  "stats": {
    "total_handles": 6,
    "successful_handles": 6,
    "total_important_tweets": 25,
    "total_filtered_tweets": 78
  }
}