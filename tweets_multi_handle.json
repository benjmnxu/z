{
  "scrape_timestamp": "2025-09-12 11:28:03",
  "handles_scraped": [
    "elonmusk",
    "sama",
    "karpathy",
    "naval",
    "pmarca",
    "AndrewYNg",
    "Emerj",
    "markgurman",
    "TechCrunch",
    "FT",
    "JustinWolfers",
    "Reuters"
  ],
  "individual_results": [
    {
      "handle": "elonmusk",
      "url": "http://127.0.0.1:8080/elonmusk",
      "scrape_timestamp": "2025-09-12 11:27:50",
      "tweets_count": 0,
      "new_tweets_count": 0,
      "skipped_tweets_count": 21,
      "tweets": [],
      "filtered_out_count": 0,
      "ai_classification_enabled": true,
      "ai_provider": "gpt",
      "handle_config": {
        "min_score": 9,
        "context": "Elon Musk tech/business content (Tesla, SpaceX, xAI, Neuralink, major announcements)"
      }
    },
    {
      "handle": "sama",
      "url": "http://127.0.0.1:8080/sama",
      "scrape_timestamp": "2025-09-12 11:27:51",
      "tweets_count": 1,
      "new_tweets_count": 0,
      "skipped_tweets_count": 19,
      "tweets": [],
      "filtered_out_count": 1,
      "ai_classification_enabled": true,
      "ai_provider": "gpt",
      "handle_config": {
        "min_score": 8,
        "context": "Sam Altman content (OpenAI, AI development, tech leadership, industry insights)"
      }
    },
    {
      "handle": "karpathy",
      "url": "http://127.0.0.1:8080/karpathy",
      "scrape_timestamp": "2025-09-12 11:27:52",
      "tweets_count": 2,
      "new_tweets_count": 2,
      "skipped_tweets_count": 19,
      "tweets": [
        {
          "tweet_url": "/karpathy/status/1965439123252281654#m",
          "tweet_id": "1965439123252281654",
          "is_retweet": false,
          "is_pinned": false,
          "author": "Andrej Karpathy",
          "username": "@karpathy",
          "date": "Sep 9",
          "full_date": "Sep 9, 2025 · 3:36 PM UTC",
          "urls": [],
          "text": "Bit silly but I still watch the Apple event livestream for new iPhones, every year since the first one in 2007. It doesn't make sense but it's ok. Livestream today at 10am (in 1.5 hours). This year, crossing my fingers again for an iPhone mini that I know won't come. rip.",
          "quoted_tweet": null,
          "media": [],
          "stats": {
            "likes": ""
          },
          "handle": "karpathy",
          "importance_score": 7,
          "importance_reason": "Company keyword (AI not available - using keywords)",
          "ai_provider": "gpt"
        },
        {
          "tweet_url": "/karpathy/status/1944435412489171119#m",
          "tweet_id": "1944435412489171119",
          "is_retweet": false,
          "is_pinned": false,
          "author": "Andrej Karpathy",
          "username": "@karpathy",
          "date": "Jul 13",
          "full_date": "Jul 13, 2025 · 4:35 PM UTC",
          "urls": [],
          "text": "Scaling up RL is all the rage right now, I had a chat with a friend about it yesterday. I'm fairly certain RL will continue to yield more intermediate gains, but I also don't expect it to be the full story. RL is basically \"hey this happened to go well (/poorly), let me slightly increase (/decrease) the probability of every action I took for the future\". You get a lot more leverage from verifier functions than explicit supervision, this is great. But first, it looks suspicious asymptotically - once the tasks grow to be minutes/hours of interaction long, you're really going to do all that work just to learn a single scalar outcome at the very end, to directly weight the gradient? Beyond asymptotics and second, this doesn't feel like the human mechanism of improvement for majority of intelligence tasks. There's significantly more bits of supervision we extract per rollout via a review/reflect stage along the lines of \"what went well? what didn't go so well? what should I try next time?\" etc. and the lessons from this stage feel explicit, like a new string to be added to the system prompt for the future, optionally to be distilled into weights (/intuition) later a bit like sleep. In English, we say something becomes \"second nature\" via this process, and we're missing learning paradigms like this. The new Memory feature is maybe a primordial version of this in ChatGPT, though it is only used for customization not problem solving. Notice that there is no equivalent of this for e.g. Atari RL because there are no LLMs and no in-context learning in those domains. \n\nExample algorithm: given a task, do a few rollouts, stuff them all into one context window (along with the reward in each case), use a meta-prompt to review/reflect on what went well or not to obtain string \"lesson\", to be added to system prompt (or more generally modify the current lessons database). Many blanks to fill in, many tweaks possible, not obvious.\n\nExample of lesson: we know LLMs can't super easily see letters due to tokenization and can't super easily count inside the residual stream, hence 'r' in 'strawberry' being famously difficult. Claude system prompt had a \"quick fix\" patch - a string was added along the lines of \"If the user asks you to count letters, first separate them by commas and increment an explicit counter each time and do the task like that\". This string is the \"lesson\", explicitly instructing the model how to complete the counting task, except the question is how this might fall out from agentic practice, instead of it being hard-coded by an engineer, how can this be generalized, and how lessons can be distilled over time to not bloat context windows indefinitely.\n\nTLDR: RL will lead to more gains because when done well, it is a lot more leveraged, bitter-lesson-pilled, and superior to SFT. It doesn't feel like the full story, especially as rollout lengths continue to expand. There are more S curves to find beyond, possibly specific to LLMs and without analogues in game/robotics-like environments, which is exciting.",
          "quoted_tweet": null,
          "media": [],
          "stats": {
            "likes": ""
          },
          "handle": "karpathy",
          "importance_score": 7,
          "importance_reason": "Company keyword (AI not available - using keywords)",
          "ai_provider": "gpt"
        }
      ],
      "filtered_out_count": 0,
      "ai_classification_enabled": true,
      "ai_provider": "gpt",
      "handle_config": {
        "min_score": 6,
        "context": "Andrej Karpathy content (AI research, machine learning, technical insights)"
      }
    },
    {
      "handle": "naval",
      "url": "http://127.0.0.1:8080/naval",
      "scrape_timestamp": "2025-09-12 11:27:53",
      "tweets_count": 0,
      "new_tweets_count": 0,
      "skipped_tweets_count": 19,
      "tweets": [],
      "filtered_out_count": 0,
      "ai_classification_enabled": true,
      "ai_provider": "gpt",
      "handle_config": {
        "min_score": 8,
        "context": "Naval Ravikant content (startups, investing, philosophy, wealth creation)"
      }
    },
    {
      "handle": "pmarca",
      "url": "http://127.0.0.1:8080/pmarca",
      "scrape_timestamp": "2025-09-12 11:27:54",
      "tweets_count": 0,
      "new_tweets_count": 0,
      "skipped_tweets_count": 21,
      "tweets": [],
      "filtered_out_count": 0,
      "ai_classification_enabled": true,
      "ai_provider": "gpt",
      "handle_config": {
        "min_score": 7,
        "context": "Marc Andreessen content (VC insights, tech trends, startups, market analysis)"
      }
    },
    {
      "handle": "AndrewYNg",
      "url": "http://127.0.0.1:8080/AndrewYNg",
      "scrape_timestamp": "2025-09-12 11:27:56",
      "tweets_count": 2,
      "new_tweets_count": 1,
      "skipped_tweets_count": 18,
      "tweets": [
        {
          "tweet_url": "/AndrewYNg/status/1960731961494004077#m",
          "tweet_id": "1960731961494004077",
          "is_retweet": false,
          "is_pinned": false,
          "author": "Andrew Ng",
          "username": "@AndrewYNg",
          "date": "Aug 27",
          "full_date": "Aug 27, 2025 · 3:51 PM UTC",
          "urls": [
            "https://www.deeplearning.ai/short-courses/agentic-knowledge-graph-construction"
          ],
          "text": "Build better RAG by letting a team of agents extract and connect your reference materials into a knowledge graph. Our new short course, “Agentic Knowledge Graph Construction,” taught by @Neo4j Innovation Lead @akollegger , shows you how.\n\nKnowledge graphs are an important way to store information accurately but they are a lot of work to build manually.\n\nIn this course you’ll learn how to build a team of agents that turn data– in this case product reviews and invoices from suppliers–into structured graphs of entities and relationships for RAG.\n\nLearn how agents can automatically handle the time-consuming work of building graphs — extracting entities and relationships (e.g., Product \"contains\" Assembly, Part \"supplied_by\" Supplier, Customer review \"mentions\" Product), deduplicating them, fact-checking them, and committing them to a graph database — so your retrieval system can find right information to generate accurate output. For example, you can use agents to help trace customer complaints directly to specific suppliers, manufacturing processes, and product hierarchies, thus turning fragmented information into queryable business intelligence.\n\nSkills you’ll gain:\n- Build, store, and access knowledge graphs using the Neo4j graph database\n- Build multi-agent systems using Google’s Agent Development Kit (ADK)\n- Set up a loop of agentic workflows to propose and refine a graph schema through fact-checking\n- Connect agent-generated graphs of unstructured and structured data into a unified knowledge graph\n\nThis course gets into the practicum of why knowledge graphs give more accurate information retrieval than vector search alone, especially for high-stakes applications where precision matters more than fuzzy similarity matching.\n\nSign up here: deeplearning.ai/short-course…",
          "quoted_tweet": null,
          "media": [
            {
              "type": "image",
              "src": "/pic/amplify_video_thumb%2F1960731242825179143%2Fimg%2Fp8H-0qyI9wF9zCLx.jpg%3Fname%3Dsmall%26format%3Dwebp",
              "alt": ""
            },
            {
              "type": "video",
              "thumbnail": "/pic/amplify_video_thumb%2F1960731242825179143%2Fimg%2Fp8H-0qyI9wF9zCLx.jpg%3Fname%3Dsmall%26format%3Dwebp"
            }
          ],
          "stats": {
            "likes": ""
          },
          "handle": "AndrewYNg",
          "importance_score": 7,
          "importance_reason": "Company keyword (AI not available - using keywords)",
          "ai_provider": "gpt"
        }
      ],
      "filtered_out_count": 1,
      "ai_classification_enabled": true,
      "ai_provider": "gpt",
      "handle_config": {
        "min_score": 7,
        "context": "andrew ng"
      }
    },
    {
      "handle": "Emerj",
      "url": "http://127.0.0.1:8080/Emerj",
      "scrape_timestamp": "2025-09-12 11:27:56",
      "tweets_count": 0,
      "new_tweets_count": 0,
      "skipped_tweets_count": 20,
      "tweets": [],
      "filtered_out_count": 0,
      "ai_classification_enabled": true,
      "ai_provider": "gpt",
      "handle_config": {
        "min_score": 7,
        "context": "Emerj"
      }
    },
    {
      "handle": "markgurman",
      "url": "http://127.0.0.1:8080/markgurman",
      "scrape_timestamp": "2025-09-12 11:27:58",
      "tweets_count": 1,
      "new_tweets_count": 1,
      "skipped_tweets_count": 17,
      "tweets": [
        {
          "tweet_url": "/markgurman/status/1965510494531584375#m",
          "tweet_id": "1965510494531584375",
          "is_retweet": false,
          "is_pinned": false,
          "author": "Mark Gurman",
          "username": "@markgurman",
          "date": "Sep 9",
          "full_date": "Sep 9, 2025 · 8:19 PM UTC",
          "urls": [
            "https://www.bloomberg.com/news/articles/2025-09-09/apple-debuts-airpods-pro-3-with-heart-rate-monitor-better-fit?srnd=undefined&embedded-checkout=true"
          ],
          "text": "Apple Inc. introduced its first new AirPods Pro model in three years, adding new health-tracking features, live translation capabilities, improved noise cancellation and a better fit. bloomberg.com/news/articles/…",
          "quoted_tweet": null,
          "media": [],
          "stats": {},
          "handle": "markgurman",
          "importance_score": 7,
          "importance_reason": "Company keyword (AI not available - using keywords)",
          "ai_provider": "gpt"
        }
      ],
      "filtered_out_count": 0,
      "ai_classification_enabled": true,
      "ai_provider": "gpt",
      "handle_config": {
        "min_score": 7,
        "context": "markgurman"
      }
    },
    {
      "handle": "TechCrunch",
      "url": "http://127.0.0.1:8080/TechCrunch",
      "scrape_timestamp": "2025-09-12 11:27:58",
      "tweets_count": 3,
      "new_tweets_count": 0,
      "skipped_tweets_count": 17,
      "tweets": [],
      "filtered_out_count": 3,
      "ai_classification_enabled": true,
      "ai_provider": "gpt",
      "handle_config": {
        "min_score": 8,
        "context": "TechCrunch"
      }
    },
    {
      "handle": "FT",
      "url": "http://127.0.0.1:8080/FT",
      "scrape_timestamp": "2025-09-12 11:27:59",
      "tweets_count": 1,
      "new_tweets_count": 0,
      "skipped_tweets_count": 20,
      "tweets": [],
      "filtered_out_count": 1,
      "ai_classification_enabled": true,
      "ai_provider": "gpt",
      "handle_config": {
        "min_score": 8,
        "context": "FT"
      }
    },
    {
      "handle": "JustinWolfers",
      "url": "http://127.0.0.1:8080/JustinWolfers",
      "scrape_timestamp": "2025-09-12 11:28:00",
      "tweets_count": 2,
      "new_tweets_count": 1,
      "skipped_tweets_count": 18,
      "tweets": [
        {
          "tweet_url": "/JustinWolfers/status/1965560004800573711#m",
          "tweet_id": "1965560004800573711",
          "is_retweet": false,
          "is_pinned": false,
          "author": "Justin Wolfers",
          "username": "@JustinWolfers",
          "date": "Sep 9",
          "full_date": "Sep 9, 2025 · 11:36 PM UTC",
          "urls": [
            "https://www.abc.net.au/about/media-centre/press-releases/2025-abc-boyer-lecture-series-examines-australia-as-a-radical-ex/105753920"
          ],
          "text": "Here's a link to the announcement: abc.net.au/about/media-centr…",
          "quoted_tweet": null,
          "media": [],
          "stats": {},
          "handle": "JustinWolfers",
          "importance_score": 8,
          "importance_reason": "High priority keyword (AI not available - using keywords)",
          "ai_provider": "gpt"
        }
      ],
      "filtered_out_count": 1,
      "ai_classification_enabled": true,
      "ai_provider": "gpt",
      "handle_config": {
        "min_score": 8,
        "context": "JustinWolfers"
      }
    },
    {
      "handle": "Reuters",
      "url": "http://127.0.0.1:8080/Reuters",
      "scrape_timestamp": "2025-09-12 11:28:01",
      "tweets_count": 1,
      "new_tweets_count": 0,
      "skipped_tweets_count": 20,
      "tweets": [],
      "filtered_out_count": 1,
      "ai_classification_enabled": true,
      "ai_provider": "gpt",
      "handle_config": {
        "min_score": 8,
        "context": "Reuters"
      }
    }
  ],
  "combined_tweets": [
    {
      "tweet_url": "/JustinWolfers/status/1965560004800573711#m",
      "tweet_id": "1965560004800573711",
      "is_retweet": false,
      "is_pinned": false,
      "author": "Justin Wolfers",
      "username": "@JustinWolfers",
      "date": "Sep 9",
      "full_date": "Sep 9, 2025 · 11:36 PM UTC",
      "urls": [
        "https://www.abc.net.au/about/media-centre/press-releases/2025-abc-boyer-lecture-series-examines-australia-as-a-radical-ex/105753920"
      ],
      "text": "Here's a link to the announcement: abc.net.au/about/media-centr…",
      "quoted_tweet": null,
      "media": [],
      "stats": {},
      "handle": "JustinWolfers",
      "importance_score": 8,
      "importance_reason": "High priority keyword (AI not available - using keywords)",
      "ai_provider": "gpt"
    },
    {
      "tweet_url": "/karpathy/status/1965439123252281654#m",
      "tweet_id": "1965439123252281654",
      "is_retweet": false,
      "is_pinned": false,
      "author": "Andrej Karpathy",
      "username": "@karpathy",
      "date": "Sep 9",
      "full_date": "Sep 9, 2025 · 3:36 PM UTC",
      "urls": [],
      "text": "Bit silly but I still watch the Apple event livestream for new iPhones, every year since the first one in 2007. It doesn't make sense but it's ok. Livestream today at 10am (in 1.5 hours). This year, crossing my fingers again for an iPhone mini that I know won't come. rip.",
      "quoted_tweet": null,
      "media": [],
      "stats": {
        "likes": ""
      },
      "handle": "karpathy",
      "importance_score": 7,
      "importance_reason": "Company keyword (AI not available - using keywords)",
      "ai_provider": "gpt"
    },
    {
      "tweet_url": "/karpathy/status/1944435412489171119#m",
      "tweet_id": "1944435412489171119",
      "is_retweet": false,
      "is_pinned": false,
      "author": "Andrej Karpathy",
      "username": "@karpathy",
      "date": "Jul 13",
      "full_date": "Jul 13, 2025 · 4:35 PM UTC",
      "urls": [],
      "text": "Scaling up RL is all the rage right now, I had a chat with a friend about it yesterday. I'm fairly certain RL will continue to yield more intermediate gains, but I also don't expect it to be the full story. RL is basically \"hey this happened to go well (/poorly), let me slightly increase (/decrease) the probability of every action I took for the future\". You get a lot more leverage from verifier functions than explicit supervision, this is great. But first, it looks suspicious asymptotically - once the tasks grow to be minutes/hours of interaction long, you're really going to do all that work just to learn a single scalar outcome at the very end, to directly weight the gradient? Beyond asymptotics and second, this doesn't feel like the human mechanism of improvement for majority of intelligence tasks. There's significantly more bits of supervision we extract per rollout via a review/reflect stage along the lines of \"what went well? what didn't go so well? what should I try next time?\" etc. and the lessons from this stage feel explicit, like a new string to be added to the system prompt for the future, optionally to be distilled into weights (/intuition) later a bit like sleep. In English, we say something becomes \"second nature\" via this process, and we're missing learning paradigms like this. The new Memory feature is maybe a primordial version of this in ChatGPT, though it is only used for customization not problem solving. Notice that there is no equivalent of this for e.g. Atari RL because there are no LLMs and no in-context learning in those domains. \n\nExample algorithm: given a task, do a few rollouts, stuff them all into one context window (along with the reward in each case), use a meta-prompt to review/reflect on what went well or not to obtain string \"lesson\", to be added to system prompt (or more generally modify the current lessons database). Many blanks to fill in, many tweaks possible, not obvious.\n\nExample of lesson: we know LLMs can't super easily see letters due to tokenization and can't super easily count inside the residual stream, hence 'r' in 'strawberry' being famously difficult. Claude system prompt had a \"quick fix\" patch - a string was added along the lines of \"If the user asks you to count letters, first separate them by commas and increment an explicit counter each time and do the task like that\". This string is the \"lesson\", explicitly instructing the model how to complete the counting task, except the question is how this might fall out from agentic practice, instead of it being hard-coded by an engineer, how can this be generalized, and how lessons can be distilled over time to not bloat context windows indefinitely.\n\nTLDR: RL will lead to more gains because when done well, it is a lot more leveraged, bitter-lesson-pilled, and superior to SFT. It doesn't feel like the full story, especially as rollout lengths continue to expand. There are more S curves to find beyond, possibly specific to LLMs and without analogues in game/robotics-like environments, which is exciting.",
      "quoted_tweet": null,
      "media": [],
      "stats": {
        "likes": ""
      },
      "handle": "karpathy",
      "importance_score": 7,
      "importance_reason": "Company keyword (AI not available - using keywords)",
      "ai_provider": "gpt"
    },
    {
      "tweet_url": "/AndrewYNg/status/1960731961494004077#m",
      "tweet_id": "1960731961494004077",
      "is_retweet": false,
      "is_pinned": false,
      "author": "Andrew Ng",
      "username": "@AndrewYNg",
      "date": "Aug 27",
      "full_date": "Aug 27, 2025 · 3:51 PM UTC",
      "urls": [
        "https://www.deeplearning.ai/short-courses/agentic-knowledge-graph-construction"
      ],
      "text": "Build better RAG by letting a team of agents extract and connect your reference materials into a knowledge graph. Our new short course, “Agentic Knowledge Graph Construction,” taught by @Neo4j Innovation Lead @akollegger , shows you how.\n\nKnowledge graphs are an important way to store information accurately but they are a lot of work to build manually.\n\nIn this course you’ll learn how to build a team of agents that turn data– in this case product reviews and invoices from suppliers–into structured graphs of entities and relationships for RAG.\n\nLearn how agents can automatically handle the time-consuming work of building graphs — extracting entities and relationships (e.g., Product \"contains\" Assembly, Part \"supplied_by\" Supplier, Customer review \"mentions\" Product), deduplicating them, fact-checking them, and committing them to a graph database — so your retrieval system can find right information to generate accurate output. For example, you can use agents to help trace customer complaints directly to specific suppliers, manufacturing processes, and product hierarchies, thus turning fragmented information into queryable business intelligence.\n\nSkills you’ll gain:\n- Build, store, and access knowledge graphs using the Neo4j graph database\n- Build multi-agent systems using Google’s Agent Development Kit (ADK)\n- Set up a loop of agentic workflows to propose and refine a graph schema through fact-checking\n- Connect agent-generated graphs of unstructured and structured data into a unified knowledge graph\n\nThis course gets into the practicum of why knowledge graphs give more accurate information retrieval than vector search alone, especially for high-stakes applications where precision matters more than fuzzy similarity matching.\n\nSign up here: deeplearning.ai/short-course…",
      "quoted_tweet": null,
      "media": [
        {
          "type": "image",
          "src": "/pic/amplify_video_thumb%2F1960731242825179143%2Fimg%2Fp8H-0qyI9wF9zCLx.jpg%3Fname%3Dsmall%26format%3Dwebp",
          "alt": ""
        },
        {
          "type": "video",
          "thumbnail": "/pic/amplify_video_thumb%2F1960731242825179143%2Fimg%2Fp8H-0qyI9wF9zCLx.jpg%3Fname%3Dsmall%26format%3Dwebp"
        }
      ],
      "stats": {
        "likes": ""
      },
      "handle": "AndrewYNg",
      "importance_score": 7,
      "importance_reason": "Company keyword (AI not available - using keywords)",
      "ai_provider": "gpt"
    },
    {
      "tweet_url": "/markgurman/status/1965510494531584375#m",
      "tweet_id": "1965510494531584375",
      "is_retweet": false,
      "is_pinned": false,
      "author": "Mark Gurman",
      "username": "@markgurman",
      "date": "Sep 9",
      "full_date": "Sep 9, 2025 · 8:19 PM UTC",
      "urls": [
        "https://www.bloomberg.com/news/articles/2025-09-09/apple-debuts-airpods-pro-3-with-heart-rate-monitor-better-fit?srnd=undefined&embedded-checkout=true"
      ],
      "text": "Apple Inc. introduced its first new AirPods Pro model in three years, adding new health-tracking features, live translation capabilities, improved noise cancellation and a better fit. bloomberg.com/news/articles/…",
      "quoted_tweet": null,
      "media": [],
      "stats": {},
      "handle": "markgurman",
      "importance_score": 7,
      "importance_reason": "Company keyword (AI not available - using keywords)",
      "ai_provider": "gpt"
    }
  ],
  "stats": {
    "total_handles": 12,
    "successful_handles": 12,
    "total_important_tweets": 5,
    "total_filtered_tweets": 8
  }
}